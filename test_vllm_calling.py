#!/usr/bin/env python3
"""
æµ‹è¯• vllm_calling.py ä¸­çš„ call_vllm_model å‡½æ•°

ä½¿ç”¨æ–¹æ³•:
    python test_vllm_calling.py --test text             # æµ‹è¯•çº¯æ–‡æœ¬è°ƒç”¨
    python test_vllm_calling.py --test image            # æµ‹è¯•å›¾ç‰‡è°ƒç”¨
    python test_vllm_calling.py --test video            # æµ‹è¯•å®Œæ•´è§†é¢‘
    python test_vllm_calling.py --test video_clip       # æµ‹è¯•è§†é¢‘ç‰‡æ®µè£å‰ª
    python test_vllm_calling.py --test function_call    # æµ‹è¯•å·¥å…·è°ƒç”¨
    python test_vllm_calling.py --test json_output      # æµ‹è¯•JSONè¾“å‡º
    python test_vllm_calling.py --test all              # è¿è¡Œæ‰€æœ‰æµ‹è¯•
"""

import sys
import json
import argparse
from pathlib import Path

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from vca import config
from vca.vllm_calling import call_vllm_model


# ========================================
# é…ç½®éƒ¨åˆ† - æ ¹æ®ä½ çš„ç¯å¢ƒä¿®æ”¹è¿™é‡Œ
# ========================================

# vLLM æœåŠ¡å™¨é…ç½®
VLLM_ENDPOINT = getattr(config, 'VLLM_ENDPOINT', 'http://localhost:8000')
MODEL_NAME = getattr(config, 'VIDEO_ANALYSIS_MODEL', 'Qwen/Qwen2-VL-7B-Instruct')

# æµ‹è¯•æ–‡ä»¶è·¯å¾„ï¼ˆè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
TEST_IMAGE_PATH = "/path/to/test_image.jpg"  # ä¿®æ”¹ä¸ºå®é™…å›¾ç‰‡è·¯å¾„
TEST_VIDEO_PATH = "/path/to/test_video.mp4"  # ä¿®æ”¹ä¸ºå®é™…è§†é¢‘è·¯å¾„


# ========================================
# æµ‹è¯•å‡½æ•°
# ========================================

def test_text_only():
    """æµ‹è¯•1: çº¯æ–‡æœ¬è°ƒç”¨ï¼ˆæœ€ç®€å•ï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: çº¯æ–‡æœ¬è°ƒç”¨")
    print("="*60)

    messages = [
        {
            "role": "system",
            "content": "You are a helpful assistant."
        },
        {
            "role": "user",
            "content": "è¯·ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ã€‚"
        }
    ]

    try:
        response = call_vllm_model(
            messages=messages,
            endpoint=VLLM_ENDPOINT,
            model_name=MODEL_NAME,
            max_tokens=200,
            temperature=0.7
        )

        print("\nå“åº”:")
        print(response.get("content", ""))
        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_image_input():
    """æµ‹è¯•2: å¸¦å›¾ç‰‡çš„è°ƒç”¨"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: å›¾ç‰‡è¾“å…¥")
    print("="*60)

    if not Path(TEST_IMAGE_PATH).exists():
        print(f"âš ï¸  è·³è¿‡æµ‹è¯•: å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ {TEST_IMAGE_PATH}")
        print("è¯·ä¿®æ”¹ TEST_IMAGE_PATH å˜é‡")
        return None

    messages = [
        {
            "role": "user",
            "content": "è¯·æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹ã€‚"
        }
    ]

    try:
        response = call_vllm_model(
            messages=messages,
            endpoint=VLLM_ENDPOINT,
            model_name=MODEL_NAME,
            image_paths=[TEST_IMAGE_PATH],
            max_tokens=500,
            temperature=0.5
        )

        print("\nå“åº”:")
        print(response.get("content", ""))
        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_video_input():
    """æµ‹è¯•3: å®Œæ•´è§†é¢‘è¾“å…¥"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: å®Œæ•´è§†é¢‘è¾“å…¥")
    print("="*60)

    if not Path(TEST_VIDEO_PATH).exists():
        print(f"âš ï¸  è·³è¿‡æµ‹è¯•: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ {TEST_VIDEO_PATH}")
        print("è¯·ä¿®æ”¹ TEST_VIDEO_PATH å˜é‡")
        return None

    messages = [
        {
            "role": "user",
            "content": "è¯·ç®€è¦æè¿°è¿™ä¸ªè§†é¢‘çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦åœºæ™¯å’ŒåŠ¨ä½œã€‚"
        }
    ]

    try:
        response = call_vllm_model(
            messages=messages,
            endpoint=VLLM_ENDPOINT,
            model_name=MODEL_NAME,
            video_path=TEST_VIDEO_PATH,
            video_fps=2.0,  # é‡‡æ ·å¸§ç‡
            do_sample_frames=True,  # è®©vLLMé‡‡æ ·å¸§
            max_tokens=800,
            temperature=0.5
        )

        print("\nå“åº”:")
        print(response.get("content", ""))
        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_video_clipping():
    """æµ‹è¯•4: è§†é¢‘ç‰‡æ®µè£å‰ª"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: è§†é¢‘ç‰‡æ®µè£å‰ª (use_local_clipping=True)")
    print("="*60)

    if not Path(TEST_VIDEO_PATH).exists():
        print(f"âš ï¸  è·³è¿‡æµ‹è¯•: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ {TEST_VIDEO_PATH}")
        print("è¯·ä¿®æ”¹ TEST_VIDEO_PATH å˜é‡")
        return None

    # è£å‰ªè§†é¢‘çš„10-20ç§’ç‰‡æ®µ
    start_time = 10.0  # ç§’
    end_time = 20.0    # ç§’

    messages = [
        {
            "role": "user",
            "content": f"è¯·è¯¦ç»†æè¿°è¿™ä¸ª{end_time - start_time}ç§’è§†é¢‘ç‰‡æ®µä¸­å‘ç”Ÿäº†ä»€ä¹ˆã€‚"
        }
    ]

    try:
        response = call_vllm_model(
            messages=messages,
            endpoint=VLLM_ENDPOINT,
            model_name=MODEL_NAME,
            video_path=TEST_VIDEO_PATH,
            video_fps=config.VIDEO_FPS,  # ä½¿ç”¨é…ç½®ä¸­çš„FPS
            video_start_time=start_time,
            video_end_time=end_time,
            use_local_clipping=True,  # ä½¿ç”¨æœ¬åœ°ffmpegè£å‰ªï¼ˆæ›´å¿«ï¼‰
            do_sample_frames=False,   # ä¸å†é‡‡æ ·
            max_tokens=1000,
            temperature=0.3
        )

        print(f"\nè£å‰ªèŒƒå›´: {start_time}s - {end_time}s")
        print("\nå“åº”:")
        print(response.get("content", ""))
        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_function_calling():
    """æµ‹è¯•5: å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯• 5: å·¥å…·è°ƒç”¨ (Function Calling)")
    print("="*60)

    # å®šä¹‰ä¸€ä¸ªç®€å•çš„å·¥å…·
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "city": {
                            "type": "string",
                            "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                        },
                        "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"],
                            "description": "æ¸©åº¦å•ä½"
                        }
                    },
                    "required": ["city"]
                }
            }
        }
    ]

    messages = [
        {
            "role": "user",
            "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
        }
    ]

    try:
        response = call_vllm_model(
            messages=messages,
            endpoint=VLLM_ENDPOINT,
            model_name=MODEL_NAME,
            tools=tools,
            tool_choice="auto",
            max_tokens=500,
            temperature=0.0
        )

        print("\nå“åº”:")
        if response.get("tool_calls"):
            print("æ¨¡å‹è°ƒç”¨äº†å·¥å…·:")
            for tool_call in response["tool_calls"]:
                print(f"  - å‡½æ•°å: {tool_call['function']['name']}")
                print(f"  - å‚æ•°: {tool_call['function']['arguments']}")
            print("\nâœ… æµ‹è¯•é€šè¿‡ï¼ˆæ¨¡å‹æ­£ç¡®è°ƒç”¨äº†å·¥å…·ï¼‰")
        else:
            print(f"æ¨¡å‹è¿”å›æ–‡æœ¬: {response.get('content', '')}")
            print("\nâš ï¸  è­¦å‘Šï¼šæ¨¡å‹æœªè°ƒç”¨å·¥å…·ï¼ˆå¯èƒ½æ¨¡å‹ä¸æ”¯æŒfunction callingï¼‰")
        return True
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_json_output():
    """æµ‹è¯•6: JSONæ ¼å¼è¾“å‡º"""
    print("\n" + "="*60)
    print("æµ‹è¯• 6: JSON æ ¼å¼è¾“å‡º")
    print("="*60)

    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ã€‚è¯·ç”¨JSONæ ¼å¼è¿”å›ç»“æœã€‚"
        },
        {
            "role": "user",
            "content": """è¯·åˆ†æä»¥ä¸‹æ•°æ®å¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š
{
  "name": "åˆ†ææŠ¥å‘Š",
  "items": [1, 5, 3, 8, 2],
  "summary": {
    "max": <æœ€å¤§å€¼>,
    "min": <æœ€å°å€¼>,
    "avg": <å¹³å‡å€¼>
  }
}"""
        }
    ]

    try:
        response = call_vllm_model(
            messages=messages,
            endpoint=VLLM_ENDPOINT,
            model_name=MODEL_NAME,
            return_json=True,  # è¦æ±‚JSONè¾“å‡º
            max_tokens=500,
            temperature=0.0
        )

        print("\nå“åº”:")
        content = response.get("content", "")
        print(content)

        # å°è¯•è§£æJSON
        try:
            parsed_json = json.loads(content)
            print("\nâœ… JSONè§£ææˆåŠŸ:")
            print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
        except json.JSONDecodeError:
            print("\nâš ï¸  è­¦å‘Šï¼šè¿”å›å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSON")

        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_frame_sequence():
    """æµ‹è¯•7: å¸§åºåˆ—è¾“å…¥ï¼ˆauto_encode_framesï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯• 7: å¸§åºåˆ—è¾“å…¥ (auto_encode_frames)")
    print("="*60)

    # è¿™ä¸ªæµ‹è¯•éœ€è¦ä¸€ä¸ªå¸§åºåˆ—ç›®å½•
    # å‡è®¾ä½ æœ‰ä¸€ä¸ªç›®å½•åŒ…å« frame_0000.jpg, frame_0001.jpg, ...
    frame_dir = Path("/path/to/frames")  # ä¿®æ”¹ä¸ºå®é™…è·¯å¾„

    if not frame_dir.exists():
        print(f"âš ï¸  è·³è¿‡æµ‹è¯•: å¸§ç›®å½•ä¸å­˜åœ¨ {frame_dir}")
        print("è¯·ä¿®æ”¹ frame_dir å˜é‡æˆ–åˆ›å»ºæµ‹è¯•å¸§")
        return None

    # è·å–æ‰€æœ‰å¸§
    frame_paths = sorted(frame_dir.glob("*.jpg"))[:30]  # åªå–å‰30å¸§

    if not frame_paths:
        print(f"âš ï¸  è·³è¿‡æµ‹è¯•: {frame_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡")
        return None

    messages = [
        {
            "role": "user",
            "content": "è¯·æè¿°è¿™ä¸ªè§†é¢‘ç‰‡æ®µçš„å†…å®¹ã€‚"
        }
    ]

    try:
        response = call_vllm_model(
            messages=messages,
            endpoint=VLLM_ENDPOINT,
            model_name=MODEL_NAME,
            image_paths=[str(p) for p in frame_paths],
            video_fps=2.0,  # å…³é”®ï¼šæŒ‡å®šå¸§çš„é‡‡æ ·ç‡
            auto_encode_frames=True,  # è‡ªåŠ¨ç¼–ç ä¸ºè§†é¢‘
            max_tokens=800,
            temperature=0.5
        )

        print(f"\nä½¿ç”¨äº† {len(frame_paths)} å¸§")
        print("\nå“åº”:")
        print(response.get("content", ""))
        print("\nâœ… æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ========================================
# ä¸»å‡½æ•°
# ========================================

def main():
    parser = argparse.ArgumentParser(
        description="æµ‹è¯• call_vllm_model å‡½æ•°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument(
        '--test',
        choices=['text', 'image', 'video', 'video_clip', 'function_call', 'json_output', 'frame_sequence', 'all'],
        default='text',
        help='é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•'
    )

    args = parser.parse_args()

    print("\n" + "ğŸš€ " * 30)
    print("call_vllm_model æµ‹è¯•å¥—ä»¶")
    print("ğŸš€ " * 30)

    print(f"\né…ç½®ä¿¡æ¯:")
    print(f"  - VLLM_ENDPOINT: {VLLM_ENDPOINT}")
    print(f"  - MODEL_NAME: {MODEL_NAME}")

    # æµ‹è¯•æ˜ å°„
    tests = {
        'text': ('çº¯æ–‡æœ¬', test_text_only),
        'image': ('å›¾ç‰‡è¾“å…¥', test_image_input),
        'video': ('å®Œæ•´è§†é¢‘', test_video_input),
        'video_clip': ('è§†é¢‘è£å‰ª', test_video_clipping),
        'function_call': ('å·¥å…·è°ƒç”¨', test_function_calling),
        'json_output': ('JSONè¾“å‡º', test_json_output),
        'frame_sequence': ('å¸§åºåˆ—', test_frame_sequence),
    }

    results = {}

    if args.test == 'all':
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        for test_key, (test_name, test_func) in tests.items():
            result = test_func()
            results[test_name] = result
    else:
        # è¿è¡Œå•ä¸ªæµ‹è¯•
        test_name, test_func = tests[args.test]
        result = test_func()
        results[test_name] = result

    # æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)

    passed = sum(1 for r in results.values() if r is True)
    failed = sum(1 for r in results.values() if r is False)
    skipped = sum(1 for r in results.values() if r is None)

    for test_name, result in results.items():
        if result is True:
            status = "âœ… é€šè¿‡"
        elif result is False:
            status = "âŒ å¤±è´¥"
        else:
            status = "â­ï¸  è·³è¿‡"
        print(f"  {test_name}: {status}")

    print(f"\næ€»è®¡: {passed} é€šè¿‡, {failed} å¤±è´¥, {skipped} è·³è¿‡")

    # è¿”å›é€€å‡ºç 
    sys.exit(0 if failed == 0 else 1)


if __name__ == "__main__":
    main()
