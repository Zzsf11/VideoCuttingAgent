========================================================
Loading environment modules...
Environment loaded.

========================================================
Job ID: 5340
Node: gpuh07
Start time: 2025å¹´ 12æœˆ 14æ—¥ æ˜ŸæœŸæ—¥ 17:34:43 CST
Command: python ./local_run.py --Audio_Path /public_hw/home/cit_shifangzhao/zsf/VideoCuttingAgent/Dataset/Audio/Mianhuicai/Mianhuicai.mp3
========================================================
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'interleaved', 'mrope_interleaved', 'mrope_section'}
You are attempting to use Flash Attention 2 without specifying a torch dtype. This might lead to unexpected behaviour
Processing audio to get captions...
âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾

================================================================================
MADMOM-BASED SEGMENTATION ANALYSIS
================================================================================

Processing Pipeline:
  1. Madmom keypoint detection + Rule-based filtering
  2. AI-based Level 1 section segmentation
  3. AI-based caption for each sub-segment
  4. Merge into two-level output format

âœ“ Audio duration: 04:37 (277.68 seconds)

================================================================================
STAGE 1: Madmom keypoint detection + Rule-based filtering
================================================================================

[Step 1.1] Detecting audio keypoints with Madmom...
æ­£åœ¨åˆ†æéŸ³é¢‘: /public_hw/home/cit_shifangzhao/zsf/VideoCuttingAgent/Dataset/Audio/Mianhuicai/Mianhuicai.mp3 ...
 -> æ£€æµ‹èŠ‚å¥ (Beats/Downbeats)...
    å‚æ•°: beats_per_bar=[4], BPMèŒƒå›´=[55.0, 215.0], transition_lambda=100
 -> æ£€æµ‹å†²å‡»ç‚¹ (Onsets, threshold=0.6, combine=3.0)...
 -> è®¡ç®—èƒ½é‡åŠ¨æ€...
 -> æ£€æµ‹é¢‘è°±é€šé‡å˜åŒ– (äººå£°/ä¹å™¨å˜åŒ–, threshold=0.3)...
    æ£€æµ‹åˆ° 351 ä¸ªé¢‘è°±å˜åŒ–ç‚¹
 -> æ£€æµ‹èƒ½é‡çªå˜ç‚¹ (threshold=0.15)...
    æ£€æµ‹åˆ° 446 ä¸ªèƒ½é‡çªå˜ç‚¹
 -> æ£€æµ‹é¢‘è°±è´¨å¿ƒå˜åŒ– (éŸ³è‰²å˜åŒ–, threshold=0.2)...
    æ£€æµ‹åˆ° 362 ä¸ªéŸ³è‰²å˜åŒ–ç‚¹
 -> è¯†åˆ«è°ƒæ€§ä¸æƒ…æ„ŸåŸºè°ƒ...

âœ“ Detected 640 keypoints
  - 96 downbeats
  - 74 onsets
  - 351 spectral changes
  - 446 energy changes
  - 362 timbre changes

[Step 1.2] Applying rule-based filtering...
  Parameters: merge_close=0.1s, min_interval=0.0s, 
              top_k=0, energy_percentile=0.0, max_segments=20
    æŒ‰ç±»å‹å½’ä¸€åŒ–å¼ºåº¦:
      - Timbre Change (éŸ³è‰²å˜åŒ–): 110 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.431, 0.714] -> å½’ä¸€åŒ– [0, 1]
      - Downbeat (é‡æ‹): 96 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.721, 0.937] -> å½’ä¸€åŒ– [0, 1]
      - Energy Change (èƒ½é‡å˜åŒ–): 120 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.577, 0.766] -> å½’ä¸€åŒ– [0, 1]
      - Spectral Change (é¢‘è°±å˜åŒ–): 251 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.553, 0.897] -> å½’ä¸€åŒ– [0, 1]
      - Strong Attack (å†²å‡»): 63 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.532, 0.937] -> å½’ä¸€åŒ– [0, 1]
    åˆå¹¶ç›¸è¿‘ç‚¹å: 608 ä¸ªå…³é”®ç‚¹ (merge_close=0.1s)
âœ“ After rule-based filtering: 608 keypoints

[Step 1.3] Applying type-based filtering...

    ğŸ·ï¸  æŒ‰ç±»å‹è¿‡æ»¤å…³é”®ç‚¹ (mode=only):
       ä¼˜å…ˆç±»å‹: ['Downbeat', 'Energy', 'Onset']
       - Timbre Change (éŸ³è‰²å˜åŒ–): 102 -> 0
       - Spectral Change (é¢‘è°±å˜åŒ–): 244 -> 0
       - Strong Attack (å†²å‡»): 57 -> 0
       è¿‡æ»¤å‰: 608 ä¸ª, è¿‡æ»¤å: 205 ä¸ª
âœ“ After type-based filtering: 205 keypoints

================================================================================
STAGE 2: AI-based Level 1 section segmentation
================================================================================

Using AI model to identify high-level sections (Intro, Verse, Chorus, etc.)...
Loading model from: /public_hw/home/cit_shifangzhao/zsf/HF/models/Qwen/Qwen3-Omni-30B-A3B-Captioner
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|â–‹         | 1/16 [00:02<00:44,  2.97s/it]Loading checkpoint shards:  12%|â–ˆâ–        | 2/16 [00:05<00:37,  2.66s/it]Loading checkpoint shards:  19%|â–ˆâ–‰        | 3/16 [00:07<00:32,  2.53s/it]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:10<00:32,  2.68s/it]Loading checkpoint shards:  31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:13<00:30,  2.81s/it]Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:16<00:28,  2.85s/it]Loading checkpoint shards:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:19<00:25,  2.88s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:22<00:23,  2.95s/it]Loading checkpoint shards:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:25<00:20,  2.95s/it]Loading checkpoint shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:28<00:18,  3.06s/it]Loading checkpoint shards:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:31<00:14,  2.95s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:34<00:11,  2.94s/it]Loading checkpoint shards:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:37<00:08,  2.89s/it]Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:40<00:05,  2.82s/it]Loading checkpoint shards:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:43<00:02,  2.87s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:45<00:00,  2.73s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:45<00:00,  2.84s/it]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
slurmstepd: error: *** JOB 5340 ON gpuh07 CANCELLED AT 2025-12-14T17:40:32 ***
