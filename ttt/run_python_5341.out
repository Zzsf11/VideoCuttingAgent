========================================================
Loading environment modules...
Environment loaded.

========================================================
Job ID: 5341
Node: gpuh04
Start time: 2025å¹´ 12æœˆ 14æ—¥ æ˜ŸæœŸæ—¥ 17:34:52 CST
Command: python ./local_run.py --Audio_Path /public_hw/home/cit_shifangzhao/zsf/VideoCuttingAgent/Dataset/Audio/Yongjibeichangqingge/Yongjibeichangqingge.mp3
========================================================
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'interleaved', 'mrope_interleaved', 'mrope_section'}
You are attempting to use Flash Attention 2 without specifying a torch dtype. This might lead to unexpected behaviour
Processing audio to get captions...
âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾

================================================================================
MADMOM-BASED SEGMENTATION ANALYSIS
================================================================================

Processing Pipeline:
  1. Madmom keypoint detection + Rule-based filtering
  2. AI-based Level 1 section segmentation
  3. AI-based caption for each sub-segment
  4. Merge into two-level output format

âœ“ Audio duration: 03:30 (210.03 seconds)

================================================================================
STAGE 1: Madmom keypoint detection + Rule-based filtering
================================================================================

[Step 1.1] Detecting audio keypoints with Madmom...
æ­£åœ¨åˆ†æéŸ³é¢‘: /public_hw/home/cit_shifangzhao/zsf/VideoCuttingAgent/Dataset/Audio/Yongjibeichangqingge/Yongjibeichangqingge.mp3 ...
 -> æ£€æµ‹èŠ‚å¥ (Beats/Downbeats)...
    å‚æ•°: beats_per_bar=[4], BPMèŒƒå›´=[55.0, 215.0], transition_lambda=100
 -> æ£€æµ‹å†²å‡»ç‚¹ (Onsets, threshold=0.6, combine=3.0)...
 -> è®¡ç®—èƒ½é‡åŠ¨æ€...
 -> æ£€æµ‹é¢‘è°±é€šé‡å˜åŒ– (äººå£°/ä¹å™¨å˜åŒ–, threshold=0.3)...
    æ£€æµ‹åˆ° 410 ä¸ªé¢‘è°±å˜åŒ–ç‚¹
 -> æ£€æµ‹èƒ½é‡çªå˜ç‚¹ (threshold=0.15)...
    æ£€æµ‹åˆ° 295 ä¸ªèƒ½é‡çªå˜ç‚¹
 -> æ£€æµ‹é¢‘è°±è´¨å¿ƒå˜åŒ– (éŸ³è‰²å˜åŒ–, threshold=0.2)...
    æ£€æµ‹åˆ° 299 ä¸ªéŸ³è‰²å˜åŒ–ç‚¹
 -> è¯†åˆ«è°ƒæ€§ä¸æƒ…æ„ŸåŸºè°ƒ...

âœ“ Detected 707 keypoints
  - 65 downbeats
  - 58 onsets
  - 410 spectral changes
  - 295 energy changes
  - 299 timbre changes

[Step 1.2] Applying rule-based filtering...
  Parameters: merge_close=0.1s, min_interval=0.0s, 
              top_k=0, energy_percentile=0.0, max_segments=20
    æŒ‰ç±»å‹å½’ä¸€åŒ–å¼ºåº¦:
      - Downbeat (é‡æ‹): 65 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.742, 0.991] -> å½’ä¸€åŒ– [0, 1]
      - Timbre Change (éŸ³è‰²å˜åŒ–): 125 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.436, 0.718] -> å½’ä¸€åŒ– [0, 1]
      - Strong Attack (å†²å‡»): 45 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.555, 0.906] -> å½’ä¸€åŒ– [0, 1]
      - Energy Change (èƒ½é‡å˜åŒ–): 108 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.575, 0.670] -> å½’ä¸€åŒ– [0, 1]
      - Spectral Change (é¢‘è°±å˜åŒ–): 364 ä¸ªç‚¹, åŸå§‹å¼ºåº¦ [0.567, 0.993] -> å½’ä¸€åŒ– [0, 1]
    åˆå¹¶ç›¸è¿‘ç‚¹å: 618 ä¸ªå…³é”®ç‚¹ (merge_close=0.1s)
âœ“ After rule-based filtering: 618 keypoints

[Step 1.3] Applying type-based filtering...

    ğŸ·ï¸  æŒ‰ç±»å‹è¿‡æ»¤å…³é”®ç‚¹ (mode=only):
       ä¼˜å…ˆç±»å‹: ['Downbeat', 'Energy', 'Onset']
       - Timbre Change (éŸ³è‰²å˜åŒ–): 118 -> 0
       - Strong Attack (å†²å‡»): 34 -> 0
       - Spectral Change (é¢‘è°±å˜åŒ–): 302 -> 0
       è¿‡æ»¤å‰: 618 ä¸ª, è¿‡æ»¤å: 164 ä¸ª
âœ“ After type-based filtering: 164 keypoints

================================================================================
STAGE 2: AI-based Level 1 section segmentation
================================================================================

Using AI model to identify high-level sections (Intro, Verse, Chorus, etc.)...
Loading model from: /public_hw/home/cit_shifangzhao/zsf/HF/models/Qwen/Qwen3-Omni-30B-A3B-Captioner
Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]Loading checkpoint shards:   6%|â–‹         | 1/16 [00:05<01:29,  5.98s/it]Loading checkpoint shards:  12%|â–ˆâ–        | 2/16 [00:12<01:28,  6.34s/it]Loading checkpoint shards:  19%|â–ˆâ–‰        | 3/16 [00:18<01:19,  6.15s/it]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:24<01:14,  6.18s/it]Loading checkpoint shards:  31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:31<01:08,  6.22s/it]Loading checkpoint shards:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:37<01:01,  6.15s/it]Loading checkpoint shards:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:43<00:55,  6.15s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:49<00:49,  6.16s/it]Loading checkpoint shards:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:55<00:43,  6.18s/it]Loading checkpoint shards:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [01:01<00:36,  6.04s/it]Loading checkpoint shards:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [01:06<00:29,  5.91s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [01:12<00:23,  5.89s/it]Loading checkpoint shards:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [01:19<00:18,  6.01s/it]Loading checkpoint shards:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [01:25<00:12,  6.12s/it]Loading checkpoint shards:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [01:31<00:06,  6.12s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:36<00:00,  5.84s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [01:36<00:00,  6.05s/it]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
slurmstepd: error: *** JOB 5341 ON gpuh04 CANCELLED AT 2025-12-14T17:40:29 ***
