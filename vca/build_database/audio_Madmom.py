"""
éŸ³é¢‘å…³é”®ç‚¹æ£€æµ‹è„šæœ¬
ä½¿ç”¨Madmomåº“æ£€æµ‹éŸ³é¢‘ä¸­çš„èŠ‚æ‹ã€å†²å‡»ç‚¹ç­‰å…³é”®æ„Ÿå®˜ç‚¹
æ”¯æŒå¯è§†åŒ–å’Œè§†é¢‘ç”Ÿæˆ
"""
# ============ Python 3.10+ å’Œ NumPy 1.24+ å…¼å®¹æ€§ä¿®å¤ ============
# å¿…é¡»åœ¨å¯¼å…¥ madmom ä¹‹å‰æ‰§è¡Œ

# ä¿®å¤ collections æ¨¡å—ï¼ˆPython 3.10+ ç§»é™¤äº†ç›´æ¥ä» collections å¯¼å…¥æŠ½è±¡åŸºç±»ï¼‰
import collections
import collections.abc
for attr in ('MutableSequence', 'Iterable', 'Mapping', 'MutableMapping', 'Callable'):
    if not hasattr(collections, attr):
        setattr(collections, attr, getattr(collections.abc, attr))

# ä¿®å¤ numpy æ¨¡å—ï¼ˆNumPy 1.24+ ç§»é™¤äº† np.float, np.int ç­‰åˆ«åï¼‰
import numpy as np
import warnings
with warnings.catch_warnings():
    warnings.simplefilter("ignore", FutureWarning)
    if not hasattr(np, 'float'):
        np.float = np.float64
    if not hasattr(np, 'int'):
        np.int = np.int64
    if not hasattr(np, 'complex'):
        np.complex = np.complex128
    if not hasattr(np, 'object'):
        np.object = np.object_
    if not hasattr(np, 'bool'):
        np.bool = np.bool_
    if not hasattr(np, 'str'):
        np.str = np.str_

# ============ å…¼å®¹æ€§ä¿®å¤ç»“æŸ ============

import os
import sys
import time
import argparse
import tempfile
import subprocess
import shutil
import json
from typing import List, Tuple
from scipy import signal as scipy_signal
from scipy.fft import rfft, rfftfreq
from pathlib import Path

import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

from madmom.features.onsets import CNNOnsetProcessor, OnsetPeakPickingProcessor
from madmom.features.downbeats import RNNDownBeatProcessor, DBNDownBeatTrackingProcessor
from madmom.features.key import CNNKeyRecognitionProcessor, key_prediction_to_label
from madmom.audio.signal import Signal
import madmom.features.downbeats as _downbeats_module
import itertools as _it

# ============ NumPy 2.x å…¼å®¹æ€§ä¿®å¤ for DBNDownBeatTrackingProcessor ============
# madmom 0.16.1 ä¸­çš„ np.asarray(results)[:, 1] åœ¨ NumPy 2.x ä¸­ä¼šå¤±è´¥
# å› ä¸º results ä¸­çš„å…ƒç´  (path, log_prob) å½¢çŠ¶ä¸ä¸€è‡´

def _patched_dbn_process(self, activations, **kwargs):
    """ä¿®å¤ NumPy 2.x å…¼å®¹æ€§çš„ DBNDownBeatTrackingProcessor.process æ–¹æ³•"""
    first = 0
    if self.threshold:
        idx = np.nonzero(activations >= self.threshold)[0]
        if idx.any():
            first = max(first, np.min(idx))
            last = min(len(activations), np.max(idx) + 1)
        else:
            last = first
        activations = activations[first:last]
    
    if not activations.any():
        return np.empty((0, 2))
    
    results = list(self.map(_downbeats_module._process_dbn, 
                            zip(self.hmms, _it.repeat(activations))))
    
    # ä¿®å¤: ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼è·å– log probabilitiesï¼Œè€Œä¸æ˜¯ np.asarray(results)[:, 1]
    log_probs = [r[1] for r in results]
    best = np.argmax(log_probs)
    
    path, _ = results[best]
    st = self.hmms[best].transition_model.state_space
    om = self.hmms[best].observation_model
    positions = st.state_positions[path]
    beat_numbers = positions.astype(int) + 1
    
    if self.correct:
        beats = np.empty(0, dtype=np.int64)  # ä¿®å¤: np.int -> np.int64
        beat_range = om.pointers[path] >= 1
        idx = np.nonzero(np.diff(beat_range.astype(np.int64)))[0] + 1  # ä¿®å¤
        if beat_range[0]:
            idx = np.r_[0, idx]
        if beat_range[-1]:
            idx = np.r_[idx, beat_range.size]
        if idx.any():
            for left, right in idx.reshape((-1, 2)):
                peak = np.argmax(activations[left:right]) // 2 + left
                beats = np.hstack((beats, peak))
    else:
        beats = np.nonzero(np.diff(beat_numbers))[0] + 1
    
    return np.vstack(((beats + first) / float(self.fps), beat_numbers[beats])).T

# åº”ç”¨ monkey-patch
DBNDownBeatTrackingProcessor.process = _patched_dbn_process
# ============ NumPy 2.x å…¼å®¹æ€§ä¿®å¤ç»“æŸ ============

# é…ç½®ä¸­æ–‡å­—ä½“
def setup_chinese_font():
    """é…ç½®matplotlibçš„ä¸­æ–‡å­—ä½“"""
    # å¸¸è§çš„ä¸­æ–‡å­—ä½“åˆ—è¡¨
    chinese_fonts = [
        'SimHei',           # é»‘ä½“
        'Microsoft YaHei',  # å¾®è½¯é›…é»‘
        'WenQuanYi Micro Hei',  # æ–‡æ³‰é©¿å¾®ç±³é»‘ (Linuxå¸¸è§)
        'Noto Sans CJK SC',     # æ€æºé»‘ä½“ç®€ä½“
        'AR PL UMing CN',       # æ–‡é¼PLç®€ä¸­æ˜ä½“
        'STSong',               # åæ–‡å®‹ä½“
        'STHeiti',              # åæ–‡é»‘ä½“
    ]

    # è·å–ç³»ç»Ÿæ‰€æœ‰å­—ä½“
    available_fonts = [f.name for f in fm.fontManager.ttflist]

    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
    for font in chinese_fonts:
        if font in available_fonts:
            plt.rcParams['font.sans-serif'] = [font, 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False
            return font

    # å¦‚æœæ‰¾ä¸åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨è‹±æ–‡æ ‡ç­¾
    print("âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾")
    return None

setup_chinese_font()

# æ·»åŠ vcaæ¨¡å—åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))
from vca.audio_utils import load_audio_no_librosa


class SensoryKeypointDetector:
    def __init__(
        self,
        # Onset æ£€æµ‹å‚æ•°
        onset_threshold: float = 0.6,
        onset_smooth: float = 0.0,
        onset_pre_avg: float = 0.0,
        onset_post_avg: float = 0.0,
        onset_pre_max: float = 0.01,
        onset_post_max: float = 0.01,
        onset_combine: float = 0.03,
        # DBN èŠ‚æ‹æ£€æµ‹å‚æ•°
        beats_per_bar: list = None,
        min_bpm: float = 55.0,
        max_bpm: float = 215.0,
        num_tempi: int = 60,
        transition_lambda: float = 100,
        observation_lambda: int = 16,
        dbn_threshold: float = 0.05,
        correct_beats: bool = True,
        fps: int = 100,
        # é¢å¤–çš„éŸ³é¢‘ç‰¹å¾æ£€æµ‹å‚æ•°
        detect_spectral_flux: bool = True,
        spectral_flux_threshold: float = 0.3,
        detect_energy_change: bool = True,
        energy_change_threshold: float = 0.15,
        detect_spectral_centroid: bool = True,
        centroid_change_threshold: float = 0.2,
    ):
        """
        éŸ³é¢‘æ„Ÿå®˜å…³é”®ç‚¹æ£€æµ‹å™¨
        
        Onset æ£€æµ‹å‚æ•°:
            onset_threshold: Onsetæ£€æµ‹é˜ˆå€¼ï¼Œå€¼è¶Šé«˜æ£€æµ‹åˆ°çš„å†²å‡»ç‚¹è¶Šå°‘ (é»˜è®¤0.6)
            onset_smooth: å¹³æ»‘æ¿€æ´»å‡½æ•°çš„çª—å£å¤§å°(ç§’) (é»˜è®¤0.0)
            onset_pre_avg: è®¡ç®—ç§»åŠ¨å¹³å‡æ—¶å‘å‰çœ‹çš„çª—å£å¤§å°(ç§’) (é»˜è®¤0.0)
            onset_post_avg: è®¡ç®—ç§»åŠ¨å¹³å‡æ—¶å‘åçœ‹çš„çª—å£å¤§å°(ç§’) (é»˜è®¤0.0)
            onset_pre_max: è®¡ç®—å±€éƒ¨æœ€å¤§å€¼æ—¶å‘å‰çœ‹çš„çª—å£å¤§å°(ç§’) (é»˜è®¤0.01)
            onset_post_max: è®¡ç®—å±€éƒ¨æœ€å¤§å€¼æ—¶å‘åçœ‹çš„çª—å£å¤§å°(ç§’) (é»˜è®¤0.01)
            onset_combine: åˆå¹¶ç›¸è¿‘onsetçš„æ—¶é—´çª—å£(ç§’) (é»˜è®¤0.03)
        
        DBN èŠ‚æ‹æ£€æµ‹å‚æ•°:
            beats_per_bar: æ¯å°èŠ‚çš„æ‹æ•°ï¼Œå¦‚[4]è¡¨ç¤º4/4æ‹ï¼Œ[3,4]åŒæ—¶æ£€æµ‹3/4å’Œ4/4æ‹ (é»˜è®¤[4])
            min_bpm: æœ€å°BPM (é»˜è®¤55.0)
            max_bpm: æœ€å¤§BPM (é»˜è®¤215.0)
            num_tempi: å»ºæ¨¡çš„é€Ÿåº¦æ•°é‡ (é»˜è®¤60)
            transition_lambda: é€Ÿåº¦å˜åŒ–çš„æŒ‡æ•°åˆ†å¸ƒå‚æ•°ï¼Œå€¼è¶Šå¤§è¶Šå€¾å‘ä¿æŒæ’å®šé€Ÿåº¦ (é»˜è®¤100)
            observation_lambda: å°†ä¸€ä¸ªèŠ‚æ‹å‘¨æœŸåˆ†æˆçš„éƒ¨åˆ†æ•° (é»˜è®¤16)
            dbn_threshold: åœ¨Viterbiè§£ç å‰å¯¹æ¿€æ´»å€¼è¿›è¡Œé˜ˆå€¼å¤„ç† (é»˜è®¤0.05)
            correct_beats: æ˜¯å¦å°†èŠ‚æ‹å¯¹é½åˆ°æœ€è¿‘çš„æ¿€æ´»å³°å€¼ (é»˜è®¤True)
            fps: å¸§ç‡ (é»˜è®¤100)
        
        é¢å¤–éŸ³é¢‘ç‰¹å¾æ£€æµ‹å‚æ•°:
            detect_spectral_flux: æ˜¯å¦æ£€æµ‹é¢‘è°±é€šé‡å˜åŒ–ï¼ˆå¯¹äººå£°/ä¹å™¨å˜åŒ–æ•æ„Ÿï¼‰(é»˜è®¤True)
            spectral_flux_threshold: é¢‘è°±é€šé‡å˜åŒ–é˜ˆå€¼ï¼Œå€¼è¶Šä½æ£€æµ‹åˆ°çš„ç‚¹è¶Šå¤š (é»˜è®¤0.3)
            detect_energy_change: æ˜¯å¦æ£€æµ‹èƒ½é‡çªå˜ç‚¹ (é»˜è®¤True)
            energy_change_threshold: èƒ½é‡å˜åŒ–é˜ˆå€¼ (é»˜è®¤0.15)
            detect_spectral_centroid: æ˜¯å¦æ£€æµ‹é¢‘è°±è´¨å¿ƒå˜åŒ–ï¼ˆéŸ³è‰²æ˜æš—å˜åŒ–ï¼‰(é»˜è®¤True)
            centroid_change_threshold: é¢‘è°±è´¨å¿ƒå˜åŒ–é˜ˆå€¼ (é»˜è®¤0.2)
        """
        # Onset å‚æ•°
        self.onset_threshold = onset_threshold
        self.onset_smooth = onset_smooth
        self.onset_pre_avg = onset_pre_avg
        self.onset_post_avg = onset_post_avg
        self.onset_pre_max = onset_pre_max
        self.onset_post_max = onset_post_max
        self.onset_combine = onset_combine
        
        # DBN å‚æ•°
        self.beats_per_bar = beats_per_bar if beats_per_bar is not None else [4]
        self.min_bpm = min_bpm
        self.max_bpm = max_bpm
        self.num_tempi = num_tempi
        self.transition_lambda = transition_lambda
        self.observation_lambda = observation_lambda
        self.dbn_threshold = dbn_threshold
        self.correct_beats = correct_beats
        self.fps = fps
        
        # é¢å¤–ç‰¹å¾æ£€æµ‹å‚æ•°
        self.detect_spectral_flux = detect_spectral_flux
        self.spectral_flux_threshold = spectral_flux_threshold
        self.detect_energy_change = detect_energy_change
        self.energy_change_threshold = energy_change_threshold
        self.detect_spectral_centroid = detect_spectral_centroid
        self.centroid_change_threshold = centroid_change_threshold

    def analyze(self, audio_path):
        print(f"æ­£åœ¨åˆ†æéŸ³é¢‘: {audio_path} ...")

        # 1. èŠ‚å¥åˆ†æ (Rhythm) - è·å–å¼ºæ‹
        print(" -> æ£€æµ‹èŠ‚å¥ (Beats/Downbeats)...")
        print(f"    å‚æ•°: beats_per_bar={self.beats_per_bar}, BPMèŒƒå›´=[{self.min_bpm}, {self.max_bpm}], "
              f"transition_lambda={self.transition_lambda}")
        beat_proc = RNNDownBeatProcessor()
        beat_act = beat_proc(audio_path)
        
        # ä½¿ç”¨ DBNDownBeatTrackingProcessorï¼ˆå·²é€šè¿‡ monkey-patch ä¿®å¤ NumPy 2.x å…¼å®¹æ€§ï¼‰
        beat_tracker = DBNDownBeatTrackingProcessor(
            beats_per_bar=self.beats_per_bar,
            min_bpm=self.min_bpm,
            max_bpm=self.max_bpm,
            num_tempi=self.num_tempi,
            transition_lambda=self.transition_lambda,
            observation_lambda=self.observation_lambda,
            threshold=self.dbn_threshold,
            correct=self.correct_beats,
            fps=self.fps
        )
        beat_info = beat_tracker(beat_act)
        beat_info = np.array(beat_info)
        
        # æå–å¼ºæ‹
        if len(beat_info) > 0:
            downbeats = beat_info[beat_info[:, 1] == 1][:, 0]
        else:
            downbeats = np.array([])
            print("    âš ï¸ æœªèƒ½æ£€æµ‹åˆ°èŠ‚æ‹")
        
        # 2. å†²å‡»åŠ›åˆ†æ (Impact) - è·å–æ˜æ˜¾çš„èµ·å§‹ç‚¹
        print(f" -> æ£€æµ‹å†²å‡»ç‚¹ (Onsets, threshold={self.onset_threshold}, combine={self.onset_combine})...")
        onset_proc = CNNOnsetProcessor()
        onset_act = onset_proc(audio_path)
        # ä½¿ç”¨å¯é…ç½®çš„é˜ˆå€¼å’Œå…¶ä»–å‚æ•°
        onset_picker = OnsetPeakPickingProcessor(
            threshold=self.onset_threshold,
            smooth=self.onset_smooth,
            pre_avg=self.onset_pre_avg,
            post_avg=self.onset_post_avg,
            pre_max=self.onset_pre_max,
            post_max=self.onset_post_max,
            combine=self.onset_combine,
            fps=self.fps
        )
        onsets = onset_picker(onset_act)

        # 3. èƒ½é‡åˆ†æ (Volume/Energy) - è®¡ç®—å‡æ–¹æ ¹ (RMS)
        # ç”¨äºåˆ¤æ–­å½“å‰æ®µè½æ˜¯æ¿€æ˜‚è¿˜æ˜¯å¹³é™
        print(" -> è®¡ç®—èƒ½é‡åŠ¨æ€...")
        sig = Signal(audio_path)
        
        # å¦‚æœæ˜¯å¤šå£°é“ï¼Œè½¬ä¸ºå•å£°é“
        if len(sig.shape) > 1:
            sig_mono = np.mean(sig, axis=1)
        else:
            sig_mono = np.array(sig)
        
        # ç®€å•çš„åˆ†å¸§è®¡ç®— RMS
        frame_size = 2048
        hop_size = 1024
        rms = []
        for i in range(0, len(sig_mono), hop_size):
            frame = sig_mono[i:i+frame_size]
            if len(frame) > 0:
                rms_val = np.sqrt(np.mean(frame**2))
                rms.append(float(rms_val))  # ç¡®ä¿æ˜¯æ ‡é‡
        rms = np.array(rms)
        avg_rms = float(np.mean(rms))
        
        # 5. é¢‘è°±é€šé‡æ£€æµ‹ (Spectral Flux) - å¯¹äººå£°å’Œä¹å™¨å˜åŒ–æ•æ„Ÿ
        spectral_flux_peaks = []
        if self.detect_spectral_flux:
            print(f" -> æ£€æµ‹é¢‘è°±é€šé‡å˜åŒ– (äººå£°/ä¹å™¨å˜åŒ–, threshold={self.spectral_flux_threshold})...")
            # è®¡ç®—çŸ­æ—¶å‚…é‡Œå¶å˜æ¢
            n_fft = 2048
            hop_length = 512
            
            # è®¡ç®—é¢‘è°±å›¾
            spectrogram = []
            for i in range(0, len(sig_mono) - n_fft, hop_length):
                frame = sig_mono[i:i+n_fft]
                windowed = frame * np.hanning(n_fft)
                spectrum = np.abs(np.fft.rfft(windowed))
                spectrogram.append(spectrum)
            spectrogram = np.array(spectrogram)
            
            if len(spectrogram) > 1:
                # è®¡ç®—é¢‘è°±é€šé‡ï¼ˆç›¸é‚»å¸§ä¹‹é—´çš„é¢‘è°±å·®å¼‚ï¼‰
                spectral_flux = np.zeros(len(spectrogram))
                for i in range(1, len(spectrogram)):
                    # åªè€ƒè™‘æ­£å‘å˜åŒ–ï¼ˆèƒ½é‡å¢åŠ ï¼‰
                    diff = spectrogram[i] - spectrogram[i-1]
                    diff = np.maximum(diff, 0)  # åªä¿ç•™æ­£å€¼
                    spectral_flux[i] = np.sum(diff)
                
                # å½’ä¸€åŒ–
                if np.max(spectral_flux) > 0:
                    spectral_flux = spectral_flux / np.max(spectral_flux)
                
                # æ£€æµ‹å³°å€¼
                from scipy.signal import find_peaks
                peaks, properties = find_peaks(
                    spectral_flux, 
                    height=self.spectral_flux_threshold,
                    distance=int(0.1 * sig.sample_rate / hop_length)  # æœ€å°é—´éš”0.1ç§’
                )
                
                # è½¬æ¢ä¸ºæ—¶é—´
                for peak_idx in peaks:
                    t = peak_idx * hop_length / sig.sample_rate
                    height = float(properties['peak_heights'][list(peaks).index(peak_idx)])
                    spectral_flux_peaks.append({'time': t, 'intensity': height})
                
                print(f"    æ£€æµ‹åˆ° {len(spectral_flux_peaks)} ä¸ªé¢‘è°±å˜åŒ–ç‚¹")
        
        # 6. èƒ½é‡çªå˜æ£€æµ‹ (Energy Change Detection)
        energy_change_peaks = []
        if self.detect_energy_change:
            print(f" -> æ£€æµ‹èƒ½é‡çªå˜ç‚¹ (threshold={self.energy_change_threshold})...")
            if len(rms) > 1:
                # è®¡ç®—RMSçš„å·®åˆ†
                rms_diff = np.abs(np.diff(rms))
                if np.max(rms_diff) > 0:
                    rms_diff_norm = rms_diff / np.max(rms_diff)
                else:
                    rms_diff_norm = rms_diff
                
                # æ£€æµ‹å³°å€¼
                from scipy.signal import find_peaks
                peaks, properties = find_peaks(
                    rms_diff_norm, 
                    height=self.energy_change_threshold,
                    distance=int(0.2 * sig.sample_rate / hop_size)  # æœ€å°é—´éš”0.2ç§’
                )
                
                for peak_idx in peaks:
                    t = peak_idx * hop_size / sig.sample_rate
                    height = float(properties['peak_heights'][list(peaks).index(peak_idx)])
                    energy_change_peaks.append({'time': t, 'intensity': height})
                
                print(f"    æ£€æµ‹åˆ° {len(energy_change_peaks)} ä¸ªèƒ½é‡çªå˜ç‚¹")
        
        # 7. é¢‘è°±è´¨å¿ƒå˜åŒ–æ£€æµ‹ (Spectral Centroid Change) - éŸ³è‰²æ˜æš—å˜åŒ–
        centroid_change_peaks = []
        if self.detect_spectral_centroid:
            print(f" -> æ£€æµ‹é¢‘è°±è´¨å¿ƒå˜åŒ– (éŸ³è‰²å˜åŒ–, threshold={self.centroid_change_threshold})...")
            n_fft = 2048
            hop_length = 512
            
            centroids = []
            for i in range(0, len(sig_mono) - n_fft, hop_length):
                frame = sig_mono[i:i+n_fft]
                windowed = frame * np.hanning(n_fft)
                spectrum = np.abs(np.fft.rfft(windowed))
                
                # è®¡ç®—é¢‘è°±è´¨å¿ƒ
                freqs = np.fft.rfftfreq(n_fft, 1/sig.sample_rate)
                if np.sum(spectrum) > 0:
                    centroid = np.sum(freqs * spectrum) / np.sum(spectrum)
                else:
                    centroid = 0
                centroids.append(centroid)
            
            centroids = np.array(centroids)
            
            if len(centroids) > 1:
                # å¹³æ»‘é¢‘è°±è´¨å¿ƒ
                from scipy.ndimage import uniform_filter1d
                centroids_smooth = uniform_filter1d(centroids, size=5)
                
                # è®¡ç®—å˜åŒ–ç‡
                centroid_diff = np.abs(np.diff(centroids_smooth))
                if np.max(centroid_diff) > 0:
                    centroid_diff_norm = centroid_diff / np.max(centroid_diff)
                else:
                    centroid_diff_norm = centroid_diff
                
                # æ£€æµ‹å³°å€¼
                from scipy.signal import find_peaks
                peaks, properties = find_peaks(
                    centroid_diff_norm, 
                    height=self.centroid_change_threshold,
                    distance=int(0.15 * sig.sample_rate / hop_length)  # æœ€å°é—´éš”0.15ç§’
                )
                
                for peak_idx in peaks:
                    t = peak_idx * hop_length / sig.sample_rate
                    height = float(properties['peak_heights'][list(peaks).index(peak_idx)])
                    centroid_change_peaks.append({'time': t, 'intensity': height})
                
                print(f"    æ£€æµ‹åˆ° {len(centroid_change_peaks)} ä¸ªéŸ³è‰²å˜åŒ–ç‚¹")

        # 8. æƒ…æ„ŸåŸºè°ƒ (Emotion Context) - è°ƒæ€§è¯†åˆ«
        print(" -> è¯†åˆ«è°ƒæ€§ä¸æƒ…æ„ŸåŸºè°ƒ...")
        key_proc = CNNKeyRecognitionProcessor()
        key_probs = key_proc(audio_path)
        key_label = key_prediction_to_label(key_probs)
        
        # ç»“æœæ•´åˆ
        timeline = []

        # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹çš„å±€éƒ¨èƒ½é‡ï¼ˆç”¨äºå¼ºåº¦è¯„ä¼°ï¼‰
        duration = len(sig_mono) / sig.sample_rate
        rms_times = np.linspace(0, duration, len(rms))
        rms_max = np.max(rms) if len(rms) > 0 else 1.0
        
        # å±€éƒ¨çª—å£å¤§å°ï¼ˆç§’ï¼‰ï¼Œç”¨äºè®¡ç®—å±€éƒ¨ç›¸å¯¹èƒ½é‡
        local_window = 10.0  # 10ç§’çª—å£
        
        def get_local_relative_energy(t):
            """
            è·å–æ—¶é—´tå¤„çš„å±€éƒ¨ç›¸å¯¹èƒ½é‡
            ä½¿ç”¨å±€éƒ¨çª—å£å†…çš„æœ€å¤§å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼Œè¿™æ ·introéƒ¨åˆ†çš„å…³é”®ç‚¹ä¹Ÿèƒ½æœ‰è¾ƒé«˜çš„ç›¸å¯¹å¼ºåº¦
            """
            if len(rms) == 0:
                return 0.5
            
            idx = np.argmin(np.abs(rms_times - t))
            current_rms = float(rms[idx])
            
            # æ‰¾åˆ°å±€éƒ¨çª—å£å†…çš„æ‰€æœ‰RMSå€¼
            window_start = max(0, t - local_window / 2)
            window_end = min(duration, t + local_window / 2)
            
            mask = (rms_times >= window_start) & (rms_times <= window_end)
            local_rms = rms[mask]
            
            if len(local_rms) == 0:
                return 0.5
            
            local_max = np.max(local_rms)
            local_min = np.min(local_rms)
            
            # å±€éƒ¨ç›¸å¯¹èƒ½é‡ï¼šåœ¨å±€éƒ¨èŒƒå›´å†…çš„ç›¸å¯¹ä½ç½®
            if local_max - local_min < 1e-10:
                local_relative = 0.5
            else:
                local_relative = (current_rms - local_min) / (local_max - local_min)
            
            # å…¨å±€ç›¸å¯¹èƒ½é‡
            global_relative = current_rms / (rms_max + 1e-10)
            
            # ç»¼åˆï¼š70% å±€éƒ¨ç›¸å¯¹ + 30% å…¨å±€ç›¸å¯¹
            # è¿™æ ·æ—¢ä¿ç•™äº†å±€éƒ¨å˜åŒ–çš„æ•æ„Ÿæ€§ï¼Œåˆä¿ç•™äº†ä¸€å®šçš„å…¨å±€ä¿¡æ¯
            return 0.7 * local_relative + 0.3 * global_relative
        
        # æ·»åŠ å¼ºæ‹äº‹ä»¶ï¼ˆå¼ºæ‹çš„åŸºç¡€å¼ºåº¦æ›´é«˜ï¼‰
        for t in downbeats:
            energy = get_local_relative_energy(t)
            # å¼ºæ‹å¼ºåº¦ = åŸºç¡€å¼ºåº¦(0.7) + èƒ½é‡åŠ æˆ(0.3)
            intensity = 0.7 + 0.3 * energy
            timeline.append({'time': float(t), 'type': 'Downbeat (é‡æ‹)', 'intensity': float(intensity)})

        # æ·»åŠ  Onset äº‹ä»¶ (ä¸ºäº†é¿å…å’Œå¼ºæ‹é‡å¤ï¼Œå¯ä»¥åšä¸ªç®€å•çš„å»é‡æˆ–æ ‡è®°)
        for t in onsets:
            # å¦‚æœè¿™ä¸ª onset è·ç¦»æŸä¸ª downbeat å¾ˆè¿‘ (<0.05s)ï¼Œåˆ™å¿½ç•¥å®ƒ(è§†ä¸ºåŒä¸€ç‚¹)
            if not np.any(np.abs(downbeats - t) < 0.05):
                energy = get_local_relative_energy(t)
                # å†²å‡»ç‚¹å¼ºåº¦ = åŸºç¡€å¼ºåº¦(0.5) + èƒ½é‡åŠ æˆ(0.5)
                intensity = 0.5 + 0.5 * energy
                timeline.append({'time': float(t), 'type': 'Strong Attack (å†²å‡»)', 'intensity': float(intensity)})
        
        # æ·»åŠ é¢‘è°±é€šé‡å˜åŒ–ç‚¹ï¼ˆäººå£°/ä¹å™¨å˜åŒ–ï¼‰
        existing_times = [kp['time'] for kp in timeline]
        for sf in spectral_flux_peaks:
            t = sf['time']
            # é¿å…ä¸å·²æœ‰ç‚¹é‡å¤
            if not any(abs(t - et) < 0.08 for et in existing_times):
                energy = get_local_relative_energy(t)
                intensity = 0.4 + 0.4 * sf['intensity'] + 0.2 * energy
                timeline.append({'time': float(t), 'type': 'Spectral Change (é¢‘è°±å˜åŒ–)', 'intensity': float(intensity)})
                existing_times.append(t)
        
        # æ·»åŠ èƒ½é‡çªå˜ç‚¹
        for ec in energy_change_peaks:
            t = ec['time']
            if not any(abs(t - et) < 0.08 for et in existing_times):
                intensity = 0.5 + 0.5 * ec['intensity']
                timeline.append({'time': float(t), 'type': 'Energy Change (èƒ½é‡å˜åŒ–)', 'intensity': float(intensity)})
                existing_times.append(t)
        
        # æ·»åŠ éŸ³è‰²å˜åŒ–ç‚¹
        for cc in centroid_change_peaks:
            t = cc['time']
            if not any(abs(t - et) < 0.08 for et in existing_times):
                energy = get_local_relative_energy(t)
                intensity = 0.35 + 0.35 * cc['intensity'] + 0.3 * energy
                timeline.append({'time': float(t), 'type': 'Timbre Change (éŸ³è‰²å˜åŒ–)', 'intensity': float(intensity)})

        # æŒ‰æ—¶é—´æ’åº
        timeline.sort(key=lambda x: x['time'])

        return {
            "meta": {
                "key": key_label,
                "avg_energy": f"{avg_rms:.4f}",
                "emotion_clue": "Happy/Bright" if "Major" in key_label else "Sad/Serious"
            },
            "keypoints": timeline,
            "downbeats": downbeats,
            "onsets": onsets,
            "spectral_flux_peaks": spectral_flux_peaks,
            "energy_change_peaks": energy_change_peaks,
            "centroid_change_peaks": centroid_change_peaks,
            "beat_info": beat_info,
            "onset_activation": onset_act,
            "rms": np.array(rms),
            "audio_signal": sig,
            "sample_rate": sig.sample_rate
        }


def filter_significant_keypoints(
    keypoints: List[dict],
    min_interval: float = 0.0,
    top_k: int = 0,
    energy_percentile: float = 0.0,
    merge_close: float = 0.1,
    segment_duration: float = 0.0,
    segment_top_k: int = 0
) -> List[dict]:
    """
    è¿‡æ»¤å…³é”®ç‚¹ï¼Œåªä¿ç•™æ˜¾è‘—çš„ç‚¹
    
    Args:
        keypoints: åŸå§‹å…³é”®ç‚¹åˆ—è¡¨
        min_interval: æœ€å°é—´éš”ï¼ˆç§’ï¼‰ï¼Œé—´éš”å†…åªä¿ç•™æœ€å¼ºçš„ç‚¹
        top_k: åªä¿ç•™å¼ºåº¦æœ€é«˜çš„å‰Kä¸ªç‚¹ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶
        energy_percentile: åªä¿ç•™å¼ºåº¦é«˜äºè¯¥ç™¾åˆ†ä½æ•°çš„ç‚¹(0-100)
        merge_close: åˆå¹¶é—´éš”å°äºæ­¤å€¼çš„ç›¸é‚»ç‚¹
        segment_duration: åˆ†æ®µæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œä¸segment_top_ké…åˆä½¿ç”¨
        segment_top_k: æ¯ä¸ªæ—¶é—´æ®µå†…ä¿ç•™çš„æœ€å¼ºç‚¹æ•°é‡ï¼Œ0è¡¨ç¤ºä¸ä½¿ç”¨åˆ†æ®µè¿‡æ»¤
    
    Returns:
        è¿‡æ»¤åçš„å…³é”®ç‚¹åˆ—è¡¨
    """
    if not keypoints:
        return []
    
    filtered = list(keypoints)
    
    # 1. åˆå¹¶ç›¸è¿‘çš„ç‚¹ï¼ˆä¿ç•™å¼ºåº¦æœ€é«˜çš„ï¼‰
    if merge_close > 0:
        filtered.sort(key=lambda x: x['time'])
        merged = []
        i = 0
        while i < len(filtered):
            # æ”¶é›†åœ¨ merge_close èŒƒå›´å†…çš„æ‰€æœ‰ç‚¹
            group = [filtered[i]]
            j = i + 1
            while j < len(filtered) and filtered[j]['time'] - filtered[i]['time'] < merge_close:
                group.append(filtered[j])
                j += 1
            # ä¿ç•™å¼ºåº¦æœ€é«˜çš„ç‚¹
            best = max(group, key=lambda x: x['intensity'])
            merged.append(best)
            i = j
        filtered = merged
        print(f"    åˆå¹¶ç›¸è¿‘ç‚¹å: {len(filtered)} ä¸ªå…³é”®ç‚¹ (merge_close={merge_close}s)")
    
    # 2. æŒ‰å¼ºåº¦ç™¾åˆ†ä½æ•°è¿‡æ»¤
    if energy_percentile > 0 and filtered:
        intensities = [kp['intensity'] for kp in filtered]
        threshold = np.percentile(intensities, energy_percentile)
        filtered = [kp for kp in filtered if kp['intensity'] >= threshold]
        print(f"    å¼ºåº¦è¿‡æ»¤å: {len(filtered)} ä¸ªå…³é”®ç‚¹ (ä¿ç•™å¼ºåº¦>={threshold:.3f}çš„ç‚¹)")
    
    # 3. æŒ‰æœ€å°é—´éš”è¿‡æ»¤ï¼ˆåœ¨æ¯ä¸ªé—´éš”å†…åªä¿ç•™æœ€å¼ºçš„ç‚¹ï¼‰
    if min_interval > 0 and filtered:
        filtered.sort(key=lambda x: x['time'])
        interval_filtered = []
        current_interval_start = filtered[0]['time']
        current_best = filtered[0]
        
        for kp in filtered[1:]:
            if kp['time'] - current_interval_start < min_interval:
                # åœ¨åŒä¸€é—´éš”å†…ï¼Œä¿ç•™å¼ºåº¦æ›´é«˜çš„
                if kp['intensity'] > current_best['intensity']:
                    current_best = kp
            else:
                # æ–°é—´éš”ï¼Œä¿å­˜ä¹‹å‰çš„æœ€ä½³ç‚¹
                interval_filtered.append(current_best)
                current_interval_start = kp['time']
                current_best = kp
        
        # æ·»åŠ æœ€åä¸€ä¸ª
        interval_filtered.append(current_best)
        filtered = interval_filtered
        print(f"    æœ€å°é—´éš”è¿‡æ»¤å: {len(filtered)} ä¸ªå…³é”®ç‚¹ (min_interval={min_interval}s)")
    
    # 4. åªä¿ç•™ top_k ä¸ª
    if top_k > 0 and len(filtered) > top_k:
        # æŒ‰å¼ºåº¦æ’åºï¼Œå–å‰kä¸ªï¼Œç„¶åå†æŒ‰æ—¶é—´æ’åº
        filtered.sort(key=lambda x: x['intensity'], reverse=True)
        filtered = filtered[:top_k]
        filtered.sort(key=lambda x: x['time'])
        print(f"    Top-K è¿‡æ»¤å: {len(filtered)} ä¸ªå…³é”®ç‚¹ (top_k={top_k})")
    
    # 5. åˆ†æ®µè¿‡æ»¤ï¼šæ¯ä¸ªæ—¶é—´æ®µä¿ç•™segment_top_kä¸ªæœ€å¼ºçš„ç‚¹ï¼ˆä¿è¯å„æ®µéƒ½æœ‰ä»£è¡¨ï¼‰
    if segment_duration > 0 and segment_top_k > 0 and filtered:
        filtered.sort(key=lambda x: x['time'])
        max_time = max(kp['time'] for kp in filtered)
        
        segment_filtered = []
        segment_start = 0
        
        while segment_start < max_time:
            segment_end = segment_start + segment_duration
            # è·å–è¯¥æ®µå†…çš„æ‰€æœ‰ç‚¹
            segment_points = [kp for kp in filtered 
                            if segment_start <= kp['time'] < segment_end]
            
            if segment_points:
                # æŒ‰å¼ºåº¦æ’åºï¼Œå–å‰segment_top_kä¸ª
                segment_points.sort(key=lambda x: x['intensity'], reverse=True)
                segment_filtered.extend(segment_points[:segment_top_k])
            
            segment_start = segment_end
        
        # æŒ‰æ—¶é—´é‡æ–°æ’åº
        segment_filtered.sort(key=lambda x: x['time'])
        filtered = segment_filtered
        print(f"    åˆ†æ®µè¿‡æ»¤å: {len(filtered)} ä¸ªå…³é”®ç‚¹ "
              f"(æ¯{segment_duration}sä¿ç•™{segment_top_k}ä¸ªæœ€å¼ºç‚¹)")
    
    return filtered


def parse_time_str(time_str: str) -> float:
    """
    è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºç§’æ•°
    æ”¯æŒæ ¼å¼: "MM:SS" æˆ– "HH:MM:SS" æˆ–ç›´æ¥æ•°å­—
    """
    if isinstance(time_str, (int, float)):
        return float(time_str)
    
    time_str = str(time_str).strip()
    parts = time_str.split(':')
    
    if len(parts) == 1:
        return float(parts[0])
    elif len(parts) == 2:
        return int(parts[0]) * 60 + float(parts[1])
    elif len(parts) == 3:
        return int(parts[0]) * 3600 + int(parts[1]) * 60 + float(parts[2])
    else:
        raise ValueError(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}")


def load_sections_from_caption(caption_path: str) -> List[dict]:
    """
    ä» caption JSON æ–‡ä»¶åŠ è½½ sections ä¿¡æ¯
    
    Args:
        caption_path: caption.json æ–‡ä»¶è·¯å¾„
    
    Returns:
        sections åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« name, start_time, end_time
    """
    with open(caption_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    sections = []
    for sec in data.get('sections', []):
        try:
            start_time = parse_time_str(sec.get('Start_Time', 0))
            end_time = parse_time_str(sec.get('End_Time', 0))
            name = sec.get('name', 'Unknown')
            
            if end_time > start_time:
                sections.append({
                    'name': name,
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': end_time - start_time
                })
        except Exception as e:
            print(f"    âš ï¸ è§£æ section å¤±è´¥: {sec.get('name', 'Unknown')} - {e}")
    
    return sections


def filter_by_sections(
    keypoints: List[dict],
    sections: List[dict],
    section_top_k: int = 3,
    section_min_interval: float = 0.0,
    section_energy_percentile: float = 0.0
) -> List[dict]:
    """
    åŸºäºéŸ³ä¹æ®µè½ï¼ˆsectionsï¼‰è¿›è¡Œå…³é”®ç‚¹è¿‡æ»¤
    ç¡®ä¿æ¯ä¸ªæ®µè½éƒ½æœ‰ä»£è¡¨æ€§çš„å…³é”®ç‚¹
    
    Args:
        keypoints: åŸå§‹å…³é”®ç‚¹åˆ—è¡¨
        sections: æ®µè½åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« name, start_time, end_time
        section_top_k: æ¯ä¸ªæ®µè½ä¿ç•™çš„æœ€å¼ºç‚¹æ•°é‡
        section_min_interval: æ¯ä¸ªæ®µè½å†…çš„æœ€å°é—´éš”
        section_energy_percentile: æ¯ä¸ªæ®µè½å†…çš„å¼ºåº¦ç™¾åˆ†ä½æ•°é˜ˆå€¼(0-100)ï¼Œåªä¿ç•™é«˜äºè¯¥é˜ˆå€¼çš„ç‚¹
    
    Returns:
        è¿‡æ»¤åçš„å…³é”®ç‚¹åˆ—è¡¨
    """
    if not keypoints or not sections:
        return keypoints
    
    filtered = []
    
    print(f"\n    ğŸ“‚ åŸºäº {len(sections)} ä¸ªéŸ³ä¹æ®µè½è¿›è¡Œè¿‡æ»¤:")
    
    for sec in sections:
        name = sec.get('name', 'Unknown')
        
        # å…¼å®¹ä¸åŒçš„é”®åå’Œæ—¶é—´æ ¼å¼
        start_val = sec.get('start_time', sec.get('Start_Time', 0))
        end_val = sec.get('end_time', sec.get('End_Time', 0))
        
        try:
            start = parse_time_str(start_val)
            end = parse_time_str(end_val)
        except Exception as e:
            print(f"       âš ï¸ è·³è¿‡æ— æ•ˆæ—¶é—´æ®µ: {name} ({start_val}-{end_val}) - {e}")
            continue
            
        duration = sec.get('duration', end - start)
        
        # è·å–è¯¥æ®µè½å†…çš„æ‰€æœ‰å…³é”®ç‚¹
        section_points = [kp for kp in keypoints 
                         if start <= kp['time'] < end]
        
        if not section_points:
            print(f"       [{name}] {start:.1f}s-{end:.1f}s: æ— å…³é”®ç‚¹")
            continue
        
        # 1. å¦‚æœè®¾ç½®äº†æ®µè½å†…ç™¾åˆ†ä½æ•°è¿‡æ»¤ï¼Œå…ˆåº”ç”¨
        if section_energy_percentile > 0 and len(section_points) > 1:
            intensities = [kp['intensity'] for kp in section_points]
            threshold = np.percentile(intensities, section_energy_percentile)
            before_count = len(section_points)
            section_points = [kp for kp in section_points if kp['intensity'] >= threshold]
            if len(section_points) < before_count:
                pass  # è¿‡æ»¤æˆåŠŸ
        
        # 2. å¦‚æœè®¾ç½®äº†æœ€å°é—´éš”ï¼Œåœ¨æ®µè½å†…åº”ç”¨
        if section_min_interval > 0 and section_points:
            section_points.sort(key=lambda x: x['time'])
            interval_filtered = []
            current_start = section_points[0]['time']
            current_best = section_points[0]
            
            for kp in section_points[1:]:
                if kp['time'] - current_start < section_min_interval:
                    if kp['intensity'] > current_best['intensity']:
                        current_best = kp
                else:
                    interval_filtered.append(current_best)
                    current_start = kp['time']
                    current_best = kp
            interval_filtered.append(current_best)
            section_points = interval_filtered
        
        # 3. æŒ‰å¼ºåº¦æ’åºï¼Œå¦‚æœè®¾ç½®äº† section_top_k åˆ™å–å‰ K ä¸ª
        section_points.sort(key=lambda x: x['intensity'], reverse=True)
        if section_top_k > 0:
            selected = section_points[:section_top_k]
        else:
            # section_top_k=0 è¡¨ç¤ºä¸é™åˆ¶æ•°é‡ï¼Œä¿ç•™æ‰€æœ‰ç»è¿‡å‰é¢è¿‡æ»¤çš„ç‚¹
            selected = section_points
        
        # ä¸ºé€‰ä¸­çš„ç‚¹æ·»åŠ æ®µè½ä¿¡æ¯
        for pt in selected:
            pt['section'] = name
        
        filtered.extend(selected)
        
        print(f"       [{name}] {start:.1f}s-{end:.1f}s ({duration:.1f}s): "
              f"ä¿ç•™ {len(selected)}/{len([kp for kp in keypoints if start <= kp['time'] < end])} ä¸ªç‚¹")
    
    # æŒ‰æ—¶é—´æ’åº
    filtered.sort(key=lambda x: x['time'])
    
    print(f"    æ®µè½è¿‡æ»¤åå…±: {len(filtered)} ä¸ªå…³é”®ç‚¹")
    
    return filtered


def load_audio(audio_path: str, sr: int = 16000) -> Tuple[np.ndarray, int]:
    """
    åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨audioread/soundfileï¼Œä¸ä½¿ç”¨librosaï¼‰

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        sr: é‡‡æ ·ç‡ï¼Œé»˜è®¤16000Hz

    Returns:
        audio: éŸ³é¢‘æ•°æ®
        sr: é‡‡æ ·ç‡
    """
    audio = load_audio_no_librosa(audio_path, sr=sr)
    return audio, sr


def visualize_keypoints(
    audio_path: str,
    result: dict,
    output_path: str = None,
    show_beats: bool = True,
    show_onsets: bool = True
):
    """
    å¯è§†åŒ–éŸ³é¢‘å’Œæ£€æµ‹åˆ°çš„å…³é”®ç‚¹

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        result: analyze()è¿”å›çš„ç»“æœå­—å…¸
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        show_beats: æ˜¯å¦æ˜¾ç¤ºèŠ‚æ‹ç‚¹
        show_onsets: æ˜¯å¦æ˜¾ç¤ºå†²å‡»ç‚¹
    """
    # è·å–æ•°æ®
    sig = result['audio_signal']
    sr = result['sample_rate']
    downbeats = result['downbeats']
    onsets = result['onsets']
    beat_info = result['beat_info']
    onset_act = result['onset_activation']
    rms = result['rms']
    
    # å¦‚æœæ˜¯å¤šå£°é“ï¼Œè½¬ä¸ºå•å£°é“
    if len(sig.shape) > 1:
        audio = np.mean(sig, axis=1)
    else:
        audio = np.array(sig)
    
    duration = len(audio) / sr
    time_audio = np.linspace(0, duration, len(audio))

    # åˆ›å»ºå›¾å½¢
    fig = plt.figure(figsize=(16, 12))

    # 1. ç»˜åˆ¶éŸ³é¢‘æ³¢å½¢
    ax1 = plt.subplot(4, 1, 1)
    ax1.plot(time_audio, audio, color='steelblue', linewidth=0.5, alpha=0.7)
    ax1.set_ylabel('Amplitude', fontsize=12)
    ax1.set_title('Audio Waveform with Keypoints', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.set_xlim(0, duration)

    # æ ‡è®°å¼ºæ‹ï¼ˆçº¢è‰²ï¼‰
    if show_beats:
        for i, t in enumerate(downbeats):
            ax1.axvline(x=t, color='red', linestyle='-', linewidth=1.5, alpha=0.8,
                       label='Downbeat' if i == 0 else '')
    
    # æ ‡è®°å†²å‡»ç‚¹ï¼ˆç»¿è‰²ï¼‰
    if show_onsets:
        for i, t in enumerate(onsets):
            ax1.axvline(x=t, color='green', linestyle='--', linewidth=1, alpha=0.6,
                       label='Onset' if i == 0 else '')

    ax1.legend(loc='upper right', fontsize=10)

    # 2. ç»˜åˆ¶æ—¶é¢‘å›¾ï¼ˆSpectrogramï¼‰
    ax2 = plt.subplot(4, 1, 2)
    nperseg = 2048
    noverlap = nperseg // 2
    f, t, Sxx = scipy_signal.spectrogram(audio, sr, nperseg=nperseg, noverlap=noverlap)
    Sxx_db = 10 * np.log10(Sxx + 1e-10)
    im = ax2.pcolormesh(t, f, Sxx_db, shading='gouraud', cmap='viridis')
    ax2.set_ylabel('Frequency (Hz)', fontsize=12)
    ax2.set_title('Spectrogram', fontsize=14, fontweight='bold')
    ax2.set_ylim(0, min(8000, sr/2))
    cbar = plt.colorbar(im, ax=ax2)
    cbar.set_label('Power (dB)', fontsize=10)

    # æ ‡è®°å…³é”®ç‚¹
    if show_beats:
        for t_pt in downbeats:
            ax2.axvline(x=t_pt, color='red', linestyle='-', linewidth=1.5, alpha=0.8)
    if show_onsets:
        for t_pt in onsets:
            ax2.axvline(x=t_pt, color='green', linestyle='--', linewidth=1, alpha=0.6)

    # 3. ç»˜åˆ¶èŠ‚æ‹ä¿¡æ¯ï¼ˆæ‰€æœ‰æ‹å­ï¼‰
    ax3 = plt.subplot(4, 1, 3)
    
    # ç»˜åˆ¶æ‰€æœ‰èŠ‚æ‹
    beat_times = beat_info[:, 0]
    beat_nums = beat_info[:, 1]
    
    # ç”¨ä¸åŒé¢œè‰²æ ‡è®°ä¸åŒæ‹å·
    colors_map = {1: 'red', 2: 'blue', 3: 'green', 4: 'orange'}
    for beat_num in np.unique(beat_nums):
        mask = beat_nums == beat_num
        times_subset = beat_times[mask]
        ax3.scatter(times_subset, [beat_num] * len(times_subset), 
                   c=colors_map.get(int(beat_num), 'gray'), 
                   s=50, alpha=0.7, label=f'Beat {int(beat_num)}')
    
    ax3.set_ylabel('Beat Number', fontsize=12)
    ax3.set_title('Beat Detection (1=Downbeat)', fontsize=14, fontweight='bold')
    ax3.set_xlim(0, duration)
    ax3.set_yticks([1, 2, 3, 4])
    ax3.grid(True, alpha=0.3)
    ax3.legend(loc='upper right', fontsize=9)

    # 4. ç»˜åˆ¶Onsetæ¿€æ´»å‡½æ•°å’ŒRMSèƒ½é‡
    ax4 = plt.subplot(4, 1, 4)
    
    # Onsetæ¿€æ´»å‡½æ•°
    onset_time = np.linspace(0, duration, len(onset_act))
    ax4.plot(onset_time, onset_act / np.max(onset_act), 
             color='orange', linewidth=1, alpha=0.8, label='Onset Activation (normalized)')
    
    # RMSèƒ½é‡
    rms_time = np.linspace(0, duration, len(rms))
    rms_norm = rms / np.max(rms)
    ax4.plot(rms_time, rms_norm, color='purple', linewidth=1, alpha=0.8, label='RMS Energy (normalized)')
    
    ax4.set_ylabel('Normalized Value', fontsize=12)
    ax4.set_xlabel('Time (s)', fontsize=12)
    ax4.set_title('Onset Activation & RMS Energy', fontsize=14, fontweight='bold')
    ax4.set_xlim(0, duration)
    ax4.grid(True, alpha=0.3)
    ax4.legend(loc='upper right', fontsize=9)

    # æ ‡è®°å…³é”®ç‚¹
    if show_beats:
        for t_pt in downbeats:
            ax4.axvline(x=t_pt, color='red', linestyle='-', linewidth=1.5, alpha=0.5)
    if show_onsets:
        for t_pt in onsets:
            ax4.axvline(x=t_pt, color='green', linestyle='--', linewidth=1, alpha=0.4)

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    if output_path is None:
        audio_file = Path(audio_path)
        output_path = audio_file.parent / f"{audio_file.stem}_madmom_keypoints.png"

    plt.savefig(str(output_path), dpi=150, bbox_inches='tight')
    print(f"\nâœ… å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_path}")

    plt.close()
    return str(output_path)


def generate_color_video(
    audio_path: str,
    keypoints: List[dict],
    output_path: str = None,
    fps: int = 30,
    resolution: Tuple[int, int] = (1920, 1080),
    color_palette: List[Tuple[int, int, int]] = None,
    params_info: dict = None
):
    """
    ç”Ÿæˆä¸€ä¸ªå¸¦æœ‰çº¯è‰²ç”»é¢çš„è§†é¢‘ï¼Œå½“é‡åˆ°å…³é”®ç‚¹æ—¶åˆ‡æ¢é¢œè‰²

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        keypoints: å…³é”®ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«'time'å­—æ®µ
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        fps: è§†é¢‘å¸§ç‡ï¼Œé»˜è®¤30
        resolution: è§†é¢‘åˆ†è¾¨ç‡ (å®½, é«˜)ï¼Œé»˜è®¤1920x1080
        color_palette: é¢œè‰²åˆ—è¡¨ï¼Œæ¯ä¸ªé¢œè‰²ä¸ºRGBå…ƒç»„ã€‚å¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è°ƒè‰²æ¿
        params_info: å‚æ•°ä¿¡æ¯å­—å…¸ï¼Œç”¨äºåœ¨è§†é¢‘ä¸­æ˜¾ç¤º
    """
    # æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
    if shutil.which('ffmpeg') is None:
        print("âŒ æœªæ‰¾åˆ°ffmpegï¼Œè¯·å®‰è£…ffmpegåé‡è¯•")
        return

    # é»˜è®¤é¢œè‰²è°ƒè‰²æ¿ï¼ˆæŸ”å’Œçš„é¢œè‰²ï¼‰
    if color_palette is None:
        color_palette = [
            (70, 130, 180),   # Steel Blue
            (255, 182, 193),  # Light Pink
            (144, 238, 144),  # Light Green
            (255, 218, 185),  # Peach
            (221, 160, 221),  # Plum
            (135, 206, 250),  # Light Sky Blue
            (255, 255, 224),  # Light Yellow
            (176, 224, 230),  # Powder Blue
            (255, 228, 225),  # Misty Rose
            (240, 230, 140),  # Khaki
            (173, 216, 230),  # Light Blue
            (255, 160, 122),  # Light Salmon
            (152, 251, 152),  # Pale Green
            (238, 130, 238),  # Violet
            (250, 250, 210),  # Light Goldenrod Yellow
        ]

    # è·å–éŸ³é¢‘æ—¶é•¿
    audio, sr = load_audio(audio_path, sr=16000)
    duration = len(audio) / sr

    # æå–å…³é”®ç‚¹æ—¶é—´
    change_points_times = sorted([kp['time'] for kp in keypoints])

    # æ„å»ºæ—¶é—´æ®µåˆ—è¡¨
    segments = []
    prev_time = 0.0
    for cp_time in change_points_times:
        if cp_time > prev_time:
            segments.append((prev_time, cp_time))
        prev_time = cp_time
    # æ·»åŠ æœ€åä¸€ä¸ªæ®µ
    if prev_time < duration:
        segments.append((prev_time, duration))

    # å¦‚æœæ²¡æœ‰åˆ†å‰²ç‚¹ï¼Œæ•´ä¸ªè§†é¢‘ä½¿ç”¨ä¸€ä¸ªé¢œè‰²
    if not segments:
        segments = [(0.0, duration)]

    print(f"\nğŸ“Š è§†é¢‘æ®µè½ä¿¡æ¯:")
    print(f"  æ€»æ—¶é•¿: {duration:.2f}ç§’")
    print(f"  æ®µè½æ•°: {len(segments)}")

    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path is None:
        audio_file = Path(audio_path)
        output_path = audio_file.parent / f"{audio_file.stem}_madmom_color_video.mp4"
    output_path = str(output_path)

    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        segment_files = []

        # ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆè§†é¢‘ç‰‡æ®µ
        for i, (start_time, end_time) in enumerate(segments):
            color = color_palette[i % len(color_palette)]
            segment_duration = end_time - start_time

            # è½¬æ¢RGBä¸ºåå…­è¿›åˆ¶
            color_hex = '#{:02x}{:02x}{:02x}'.format(*color)

            segment_file = os.path.join(temp_dir, f"segment_{i:04d}.mp4")
            segment_files.append(segment_file)

            if i < 10 or i >= len(segments) - 3:  # åªæ‰“å°å‰10ä¸ªå’Œæœ€å3ä¸ª
                print(f"  æ®µè½ {i+1}: {start_time:.2f}s - {end_time:.2f}s (é¢œè‰²: {color_hex})")
            elif i == 10:
                print(f"  ... (å…± {len(segments)} ä¸ªæ®µè½)")

            # æ„å»ºå‚æ•°æ˜¾ç¤ºæ–‡æœ¬
            if params_info:
                # æ ¼å¼åŒ–å‚æ•°ä¿¡æ¯
                param_lines = []
                param_lines.append(f"Method: Madmom")
                param_lines.append(f"Onset Threshold: {params_info.get('onset_threshold', 'N/A')}")
                param_lines.append(f"Key: {params_info.get('key', 'N/A')}")
                param_lines.append(f"Emotion: {params_info.get('emotion', 'N/A')}")
                param_lines.append(f"Keypoints: {params_info.get('n_keypoints', 'N/A')}")
                param_lines.append(f"Segment: {i+1}/{len(segments)}")
                param_lines.append(f"Time: {start_time:.2f}s - {end_time:.2f}s")

                # æ ¹æ®èƒŒæ™¯é¢œè‰²é€‰æ‹©æ–‡å­—é¢œè‰²
                brightness = (color[0] * 299 + color[1] * 587 + color[2] * 114) / 1000
                text_color = 'white' if brightness < 128 else 'black'

                # è®¡ç®—å­—ä½“å¤§å°
                font_size = max(16, resolution[1] // 30)

                # æŸ¥æ‰¾å¯ç”¨çš„å­—ä½“æ–‡ä»¶
                font_paths = [
                    '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
                    '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf',
                    '/usr/share/fonts/TTF/DejaVuSans.ttf',
                    '/usr/share/fonts/dejavu/DejaVuSans.ttf',
                    '/usr/share/fonts/truetype/freefont/FreeSans.ttf',
                    '/System/Library/Fonts/Helvetica.ttc',
                    'C:/Windows/Fonts/arial.ttf',
                ]

                font_file = None
                for fp in font_paths:
                    if os.path.exists(fp):
                        font_file = fp
                        break

                if font_file:
                    # æ„å»ºå¤šè¡Œæ–‡å­—æ»¤é•œ
                    drawtext_filters = []
                    for idx, line in enumerate(param_lines):
                        y_pos = 20 + idx * (font_size + 8)
                        escaped_line = line.replace(":", r"\:").replace("'", r"\'")
                        drawtext_filters.append(
                            f"drawtext=fontfile='{font_file}':text='{escaped_line}':"
                            f"x=20:y={y_pos}:fontsize={font_size}:fontcolor={text_color}"
                        )

                    filter_chain = ','.join(drawtext_filters)

                    cmd = [
                        'ffmpeg', '-y',
                        '-f', 'lavfi',
                        '-i', f'color=c={color_hex}:s={resolution[0]}x{resolution[1]}:r={fps}:d={segment_duration}',
                        '-vf', filter_chain,
                        '-c:v', 'libx264',
                        '-pix_fmt', 'yuv420p',
                        '-t', str(segment_duration),
                        segment_file
                    ]
                else:
                    cmd = [
                        'ffmpeg', '-y',
                        '-f', 'lavfi',
                        '-i', f'color=c={color_hex}:s={resolution[0]}x{resolution[1]}:r={fps}:d={segment_duration}',
                        '-c:v', 'libx264',
                        '-pix_fmt', 'yuv420p',
                        '-t', str(segment_duration),
                        segment_file
                    ]
            else:
                cmd = [
                    'ffmpeg', '-y',
                    '-f', 'lavfi',
                    '-i', f'color=c={color_hex}:s={resolution[0]}x{resolution[1]}:r={fps}:d={segment_duration}',
                    '-c:v', 'libx264',
                    '-pix_fmt', 'yuv420p',
                    '-t', str(segment_duration),
                    segment_file
                ]

            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                print(f"âŒ ç”Ÿæˆæ®µè½ {i+1} å¤±è´¥: {result.stderr}")
                return

        # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨ç”¨äºconcat
        concat_list_file = os.path.join(temp_dir, 'concat_list.txt')
        with open(concat_list_file, 'w') as f:
            for segment_file in segment_files:
                f.write(f"file '{segment_file}'\n")

        # åˆå¹¶æ‰€æœ‰è§†é¢‘æ®µï¼ˆæ— éŸ³é¢‘ï¼‰
        temp_video = os.path.join(temp_dir, 'temp_video.mp4')
        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_list_file,
            '-c', 'copy',
            temp_video
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"âŒ åˆå¹¶è§†é¢‘æ®µå¤±è´¥: {result.stderr}")
            return

        # æ·»åŠ éŸ³é¢‘
        print(f"\nğŸµ æ­£åœ¨æ·»åŠ éŸ³é¢‘...")
        cmd = [
            'ffmpeg', '-y',
            '-i', temp_video,
            '-i', audio_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-b:a', '192k',
            '-shortest',
            output_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"âŒ æ·»åŠ éŸ³é¢‘å¤±è´¥: {result.stderr}")
            return

    print(f"\nâœ… è§†é¢‘å·²ä¿å­˜åˆ°: {output_path}")
    return output_path


def main():
    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨Madmomæ£€æµ‹éŸ³é¢‘å…³é”®ç‚¹ï¼ˆèŠ‚æ‹ã€å†²å‡»ç‚¹ç­‰ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # é»˜è®¤æ£€æµ‹
  python audio_Madmom.py audio.wav

  # æ£€æµ‹å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡
  python audio_Madmom.py audio.wav --visualize

  # è°ƒæ•´onseté˜ˆå€¼ï¼ˆå€¼è¶Šé«˜æ£€æµ‹åˆ°çš„å†²å‡»ç‚¹è¶Šå°‘ï¼‰
  python audio_Madmom.py audio.wav --onset-threshold 0.8 --visualize

  # æ£€æµ‹3/4æ‹æˆ–4/4æ‹çš„éŸ³ä¹
  python audio_Madmom.py audio.wav --beats-per-bar 3 4

  # æŒ‡å®šBPMèŒƒå›´ï¼ˆé€‚ç”¨äºå·²çŸ¥é€Ÿåº¦çš„éŸ³ä¹ï¼‰
  python audio_Madmom.py audio.wav --min-bpm 80 --max-bpm 120

  # ä½¿ç”¨é«˜transition-lambdaä¿æŒç¨³å®šèŠ‚æ‹ï¼ˆé€‚åˆèŠ‚å¥ç¨³å®šçš„éŸ³ä¹ï¼‰
  python audio_Madmom.py audio.wav --transition-lambda 200

  # ç”Ÿæˆé¢œè‰²å˜åŒ–è§†é¢‘
  python audio_Madmom.py audio.wav --video

  # ç”Ÿæˆè‡ªå®šä¹‰åˆ†è¾¨ç‡å’Œå¸§ç‡çš„è§†é¢‘
  python audio_Madmom.py audio.wav --video --resolution 1280x720 --video-fps 24

  # åŒæ—¶ç”Ÿæˆå›¾ç‰‡å’Œè§†é¢‘
  python audio_Madmom.py audio.wav --visualize --video

  # åªä½¿ç”¨å¼ºæ‹ä½œä¸ºåˆ†å‰²ç‚¹ï¼ˆå‡å°‘åˆ†å‰²æ•°é‡ï¼‰
  python audio_Madmom.py audio.wav --video --downbeats-only

  # ===== æ˜¾è‘—æ€§è¿‡æ»¤ç¤ºä¾‹ï¼ˆå‡å°‘å…³é”®ç‚¹æ•°é‡ï¼‰ =====
  
  # åªä¿ç•™å¼ºåº¦æœ€é«˜çš„20ä¸ªå…³é”®ç‚¹
  python audio_Madmom.py audio.wav --top-k 20 --video

  # è®¾ç½®æœ€å°é—´éš”0.5ç§’ï¼Œæ¯0.5ç§’å†…åªä¿ç•™æœ€å¼ºçš„ä¸€ä¸ªç‚¹
  python audio_Madmom.py audio.wav --min-interval 0.5 --video

  # åªä¿ç•™å¼ºåº¦é«˜äº50%ç™¾åˆ†ä½æ•°çš„ç‚¹ï¼ˆå»æ‰ä¸€åŠå¼±ç‚¹ï¼‰
  python audio_Madmom.py audio.wav --energy-percentile 50 --video

  # åˆå¹¶é—´éš”å°äº0.2ç§’çš„ç›¸é‚»ç‚¹ï¼ˆå‡å°‘ç¢ç‰‡åŒ–ï¼‰
  python audio_Madmom.py audio.wav --merge-close 0.2 --video

  # ç»¼åˆè¿‡æ»¤ï¼šåˆå¹¶ç›¸è¿‘ç‚¹ + æœ€å°é—´éš” + åªå–å‰30ä¸ªæœ€å¼ºç‚¹
  python audio_Madmom.py audio.wav --merge-close 0.15 --min-interval 0.3 --top-k 30 --video

  # ===== åˆ†æ®µå‡åŒ€é‡‡æ ·ï¼ˆä¿ç•™introç­‰ä½èƒ½é‡æ®µçš„å…³é”®ç‚¹ï¼‰ =====
  
  # æ¯10ç§’ä¿ç•™3ä¸ªæœ€å¼ºç‚¹ï¼ˆç¡®ä¿å„æ—¶é—´æ®µéƒ½æœ‰ä»£è¡¨ï¼‰
  python audio_Madmom.py audio.wav --segment-duration 10 --segment-top-k 3 --video

  # å…ˆåˆå¹¶ç›¸è¿‘ç‚¹ï¼Œå†åˆ†æ®µé‡‡æ ·
  python audio_Madmom.py audio.wav --merge-close 0.2 --segment-duration 15 --segment-top-k 5 --video

  # ===== åŸºäº caption æ®µè½è¿‡æ»¤ï¼ˆæ¨èæ–¹å¼ï¼‰ =====
  
  # æ ¹æ® caption.json ä¸­çš„ sections åˆ’åˆ†ï¼Œæ¯æ®µä¿ç•™3ä¸ªæœ€å¼ºç‚¹
  python audio_Madmom.py audio.wav --caption captions.json --section-top-k 3 --video

  # æ¯æ®µä¿ç•™5ä¸ªç‚¹ï¼Œæ®µå†…æœ€å°é—´éš”0.5ç§’
  python audio_Madmom.py audio.wav --caption captions.json --section-top-k 5 --section-min-interval 0.5 --video

  # æ¯æ®µåªä¿ç•™å¼ºåº¦é«˜äº50%ç™¾åˆ†ä½çš„ç‚¹ï¼Œç„¶åå–å‰3ä¸ª
  python audio_Madmom.py audio.wav --caption captions.json --section-energy-percentile 50 --section-top-k 3 --video

  # å®Œæ•´å‚æ•°ç¤ºä¾‹
  python audio_Madmom.py audio.wav --onset-threshold 0.7 --beats-per-bar 4 \\
      --min-bpm 60 --max-bpm 180 --transition-lambda 100 --visualize --video
        """
    )
    parser.add_argument('audio_path', type=str, help='éŸ³é¢‘æ–‡ä»¶è·¯å¾„')
    
    # === Onset æ£€æµ‹å‚æ•° ===
    onset_group = parser.add_argument_group('Onsetæ£€æµ‹å‚æ•°')
    onset_group.add_argument('--onset-threshold', type=float, default=0.6,
                        help='Onsetæ£€æµ‹é˜ˆå€¼ï¼Œé»˜è®¤0.6ï¼ˆå€¼è¶Šé«˜æ£€æµ‹åˆ°çš„å†²å‡»ç‚¹è¶Šå°‘ï¼‰')
    onset_group.add_argument('--onset-smooth', type=float, default=0.5,
                        help='å¹³æ»‘æ¿€æ´»å‡½æ•°çš„çª—å£å¤§å°(ç§’)ï¼Œé»˜è®¤0.0')
    onset_group.add_argument('--onset-pre-avg', type=float, default=0.5,
                        help='è®¡ç®—ç§»åŠ¨å¹³å‡æ—¶å‘å‰çœ‹çš„çª—å£å¤§å°(ç§’)ï¼Œé»˜è®¤0.0')
    onset_group.add_argument('--onset-post-avg', type=float, default=0.5,
                        help='è®¡ç®—ç§»åŠ¨å¹³å‡æ—¶å‘åçœ‹çš„çª—å£å¤§å°(ç§’)ï¼Œé»˜è®¤0.0')
    onset_group.add_argument('--onset-pre-max', type=float, default=0.5,
                        help='è®¡ç®—å±€éƒ¨æœ€å¤§å€¼æ—¶å‘å‰çœ‹çš„çª—å£å¤§å°(ç§’)ï¼Œé»˜è®¤0.01')
    onset_group.add_argument('--onset-post-max', type=float, default=0.5,
                        help='è®¡ç®—å±€éƒ¨æœ€å¤§å€¼æ—¶å‘åçœ‹çš„çª—å£å¤§å°(ç§’)ï¼Œé»˜è®¤0.01')
    onset_group.add_argument('--onset-combine', type=float, default=3,
                        help='åˆå¹¶ç›¸è¿‘onsetçš„æ—¶é—´çª—å£(ç§’)ï¼Œé»˜è®¤0.03')
    
    # === DBN èŠ‚æ‹æ£€æµ‹å‚æ•° ===
    beat_group = parser.add_argument_group('DBNèŠ‚æ‹æ£€æµ‹å‚æ•°')
    beat_group.add_argument('--beats-per-bar', type=int, nargs='+', default=[4],
                        help='æ¯å°èŠ‚çš„æ‹æ•°ï¼Œå¯æŒ‡å®šå¤šä¸ªå€¼å¦‚"3 4"åŒæ—¶æ£€æµ‹3/4å’Œ4/4æ‹ï¼Œé»˜è®¤[4]')
    beat_group.add_argument('--min-bpm', type=float, default=55.0,
                        help='æœ€å°BPMï¼Œé»˜è®¤55.0')
    beat_group.add_argument('--max-bpm', type=float, default=215.0,
                        help='æœ€å¤§BPMï¼Œé»˜è®¤215.0')
    beat_group.add_argument('--num-tempi', type=int, default=60,
                        help='å»ºæ¨¡çš„é€Ÿåº¦æ•°é‡ï¼Œé»˜è®¤60')
    beat_group.add_argument('--transition-lambda', type=float, default=100,
                        help='é€Ÿåº¦å˜åŒ–åˆ†å¸ƒå‚æ•°ï¼Œå€¼è¶Šå¤§è¶Šå€¾å‘ä¿æŒæ’å®šé€Ÿåº¦ï¼Œé»˜è®¤100')
    beat_group.add_argument('--observation-lambda', type=int, default=16,
                        help='å°†ä¸€ä¸ªèŠ‚æ‹å‘¨æœŸåˆ†æˆçš„éƒ¨åˆ†æ•°ï¼Œé»˜è®¤16')
    beat_group.add_argument('--dbn-threshold', type=float, default=0.2,
                        help='DBNæ¿€æ´»å€¼é˜ˆå€¼ï¼Œé»˜è®¤0.05')
    beat_group.add_argument('--no-correct-beats', action='store_true',
                        help='ä¸å¯¹é½èŠ‚æ‹åˆ°æœ€è¿‘çš„æ¿€æ´»å³°å€¼')
    beat_group.add_argument('--fps', type=int, default=100,
                        help='å¸§ç‡(ç”¨äºèŠ‚æ‹æ£€æµ‹)ï¼Œé»˜è®¤100')
    
    # === é¢å¤–éŸ³é¢‘ç‰¹å¾æ£€æµ‹å‚æ•° ===
    feature_group = parser.add_argument_group('é¢å¤–éŸ³é¢‘ç‰¹å¾æ£€æµ‹å‚æ•°ï¼ˆäººå£°/ä¹å™¨å˜åŒ–ï¼‰')
    feature_group.add_argument('--no-spectral-flux', action='store_true',
                        help='ç¦ç”¨é¢‘è°±é€šé‡æ£€æµ‹ï¼ˆäººå£°/ä¹å™¨å˜åŒ–ï¼‰')
    feature_group.add_argument('--spectral-flux-threshold', type=float, default=0.3,
                        help='é¢‘è°±é€šé‡å˜åŒ–é˜ˆå€¼ï¼Œå€¼è¶Šä½æ£€æµ‹è¶Šæ•æ„Ÿï¼Œé»˜è®¤0.3')
    feature_group.add_argument('--no-energy-change', action='store_true',
                        help='ç¦ç”¨èƒ½é‡çªå˜æ£€æµ‹')
    feature_group.add_argument('--energy-change-threshold', type=float, default=0.15,
                        help='èƒ½é‡å˜åŒ–é˜ˆå€¼ï¼Œå€¼è¶Šä½æ£€æµ‹è¶Šæ•æ„Ÿï¼Œé»˜è®¤0.15')
    feature_group.add_argument('--no-centroid-change', action='store_true',
                        help='ç¦ç”¨é¢‘è°±è´¨å¿ƒå˜åŒ–æ£€æµ‹ï¼ˆéŸ³è‰²å˜åŒ–ï¼‰')
    feature_group.add_argument('--centroid-change-threshold', type=float, default=0.2,
                        help='é¢‘è°±è´¨å¿ƒå˜åŒ–é˜ˆå€¼ï¼Œå€¼è¶Šä½æ£€æµ‹è¶Šæ•æ„Ÿï¼Œé»˜è®¤0.2')
    
    # === è¾“å‡ºå‚æ•° ===
    output_group = parser.add_argument_group('è¾“å‡ºå‚æ•°')
    output_group.add_argument('--visualize', '-v', action='store_true',
                        help='ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡ï¼ˆåŒ…å«æ³¢å½¢ã€æ—¶é¢‘å›¾ã€èŠ‚æ‹å’Œèƒ½é‡ï¼‰')
    output_group.add_argument('--video', action='store_true',
                        help='ç”Ÿæˆé¢œè‰²å˜åŒ–è§†é¢‘ï¼ˆçº¯è‰²ç”»é¢é…éŸ³é¢‘ï¼Œå…³é”®ç‚¹å¤„åˆ‡æ¢é¢œè‰²ï¼‰')
    output_group.add_argument('--output', '-o', type=str, default=None,
                        help='å¯è§†åŒ–å›¾ç‰‡æˆ–è§†é¢‘è¾“å‡ºè·¯å¾„')
    output_group.add_argument('--video-fps', type=int, default=30,
                        help='ç”Ÿæˆè§†é¢‘çš„å¸§ç‡ï¼Œé»˜è®¤30')
    output_group.add_argument('--resolution', type=str, default='1920x1080',
                        help='ç”Ÿæˆè§†é¢‘çš„åˆ†è¾¨ç‡ï¼Œé»˜è®¤1920x1080')
    output_group.add_argument('--downbeats-only', action='store_true',
                        help='åªä½¿ç”¨å¼ºæ‹ä½œä¸ºåˆ†å‰²ç‚¹ï¼ˆå‡å°‘åˆ†å‰²æ•°é‡ï¼‰')
    output_group.add_argument('--show-beats', action='store_true', default=True,
                        help='åœ¨å¯è§†åŒ–ä¸­æ˜¾ç¤ºèŠ‚æ‹ç‚¹')
    output_group.add_argument('--show-onsets', action='store_true', default=True,
                        help='åœ¨å¯è§†åŒ–ä¸­æ˜¾ç¤ºå†²å‡»ç‚¹')
    
    # === æ˜¾è‘—æ€§è¿‡æ»¤å‚æ•° ===
    filter_group = parser.add_argument_group('æ˜¾è‘—æ€§è¿‡æ»¤å‚æ•°')
    filter_group.add_argument('--min-interval', type=float, default=0.0,
                        help='å…³é”®ç‚¹ä¹‹é—´çš„æœ€å°é—´éš”(ç§’)ï¼Œé—´éš”å†…åªä¿ç•™æœ€å¼ºçš„ç‚¹ï¼Œé»˜è®¤0.0ï¼ˆä¸è¿‡æ»¤ï¼‰')
    filter_group.add_argument('--top-k', type=int, default=0,
                        help='åªä¿ç•™å¼ºåº¦æœ€é«˜çš„å‰Kä¸ªå…³é”®ç‚¹ï¼Œé»˜è®¤0ï¼ˆä¸é™åˆ¶ï¼‰')
    filter_group.add_argument('--energy-percentile', type=float, default=0.0,
                        help='åªä¿ç•™èƒ½é‡é«˜äºè¯¥ç™¾åˆ†ä½æ•°çš„ç‚¹(0-100)ï¼Œé»˜è®¤0ï¼ˆä¸è¿‡æ»¤ï¼‰')
    filter_group.add_argument('--merge-close', type=float, default=0.1,
                        help='åˆå¹¶é—´éš”å°äºæ­¤å€¼(ç§’)çš„ç›¸é‚»å…³é”®ç‚¹ï¼Œé»˜è®¤0.1')
    filter_group.add_argument('--segment-duration', type=float, default=0.0,
                        help='åˆ†æ®µæ—¶é•¿(ç§’)ï¼Œä¸--segment-top-ké…åˆä½¿ç”¨ï¼Œç¡®ä¿æ¯æ®µéƒ½æœ‰å…³é”®ç‚¹ï¼Œé»˜è®¤0ï¼ˆä¸åˆ†æ®µï¼‰')
    filter_group.add_argument('--segment-top-k', type=int, default=0,
                        help='æ¯ä¸ªæ—¶é—´æ®µå†…ä¿ç•™çš„æœ€å¼ºç‚¹æ•°é‡ï¼Œé»˜è®¤0ï¼ˆä¸ä½¿ç”¨åˆ†æ®µè¿‡æ»¤ï¼‰')
    
    # === åŸºäº Caption æ®µè½è¿‡æ»¤å‚æ•° ===
    caption_group = parser.add_argument_group('åŸºäºCaptionæ®µè½è¿‡æ»¤å‚æ•°')
    caption_group.add_argument('--caption', type=str, default=None,
                        help='caption.json æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºè¯»å–éŸ³ä¹æ®µè½(sections)åˆ’åˆ†')
    caption_group.add_argument('--section-top-k', type=int, default=0,
                        help='æ¯ä¸ªéŸ³ä¹æ®µè½å†…ä¿ç•™çš„æœ€å¼ºç‚¹æ•°é‡ï¼Œé»˜è®¤0')
    caption_group.add_argument('--section-min-interval', type=float, default=0.0,
                        help='æ¯ä¸ªéŸ³ä¹æ®µè½å†…çš„æœ€å°é—´éš”(ç§’)ï¼Œé»˜è®¤0ï¼ˆä¸é™åˆ¶ï¼‰')
    caption_group.add_argument('--section-energy-percentile', type=float, default=70.0,
                        help='æ¯ä¸ªéŸ³ä¹æ®µè½å†…çš„å¼ºåº¦ç™¾åˆ†ä½æ•°é˜ˆå€¼(0-100)ï¼Œåªä¿ç•™é«˜äºè¯¥é˜ˆå€¼çš„ç‚¹ï¼Œé»˜è®¤0ï¼ˆä¸è¿‡æ»¤ï¼‰')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.audio_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.audio_path}")
        return

    print(f"\n{'='*60}")
    print(f"ğŸµ Madmom éŸ³é¢‘å…³é”®ç‚¹æ£€æµ‹")
    print(f"{'='*60}")

    start_time = time.time()

    try:
        # åˆ›å»ºæ£€æµ‹å™¨å¹¶åˆ†æï¼ˆä¼ å…¥æ‰€æœ‰å‚æ•°ï¼‰
        detector = SensoryKeypointDetector(
            # Onset å‚æ•°
            onset_threshold=args.onset_threshold,
            onset_smooth=args.onset_smooth,
            onset_pre_avg=args.onset_pre_avg,
            onset_post_avg=args.onset_post_avg,
            onset_pre_max=args.onset_pre_max,
            onset_post_max=args.onset_post_max,
            onset_combine=args.onset_combine,
            # DBN å‚æ•°
            beats_per_bar=args.beats_per_bar,
            min_bpm=args.min_bpm,
            max_bpm=args.max_bpm,
            num_tempi=args.num_tempi,
            transition_lambda=args.transition_lambda,
            observation_lambda=args.observation_lambda,
            dbn_threshold=args.dbn_threshold,
            correct_beats=not args.no_correct_beats,
            fps=args.fps,
            # é¢å¤–ç‰¹å¾æ£€æµ‹å‚æ•°
            detect_spectral_flux=not args.no_spectral_flux,
            spectral_flux_threshold=args.spectral_flux_threshold,
            detect_energy_change=not args.no_energy_change,
            energy_change_threshold=args.energy_change_threshold,
            detect_spectral_centroid=not args.no_centroid_change,
            centroid_change_threshold=args.centroid_change_threshold,
        )
        result = detector.analyze(args.audio_path)

        elapsed_time = time.time() - start_time

        # è¾“å‡ºç»“æœ
        print(f"\n{'='*50}")
        print(f"æ£€æµ‹å®Œæˆ! è€—æ—¶: {elapsed_time:.2f}ç§’")
        print(f"{'='*50}")
        
        print(f"\nğŸ“Š åˆ†ææŠ¥å‘Š:")
        print(f"  æ•´ä½“åŸºè°ƒ: {result['meta']['key']} ({result['meta']['emotion_clue']})")
        print(f"  å¹³å‡èƒ½é‡: {result['meta']['avg_energy']}")
        print(f"  æ£€æµ‹åˆ° {len(result['downbeats'])} ä¸ªå¼ºæ‹")
        print(f"  æ£€æµ‹åˆ° {len(result['onsets'])} ä¸ªå†²å‡»ç‚¹")
        if result.get('spectral_flux_peaks'):
            print(f"  æ£€æµ‹åˆ° {len(result['spectral_flux_peaks'])} ä¸ªé¢‘è°±å˜åŒ–ç‚¹ (äººå£°/ä¹å™¨)")
        if result.get('energy_change_peaks'):
            print(f"  æ£€æµ‹åˆ° {len(result['energy_change_peaks'])} ä¸ªèƒ½é‡çªå˜ç‚¹")
        if result.get('centroid_change_peaks'):
            print(f"  æ£€æµ‹åˆ° {len(result['centroid_change_peaks'])} ä¸ªéŸ³è‰²å˜åŒ–ç‚¹")
        print(f"  åŸå§‹å…³é”®ç‚¹: {len(result['keypoints'])} ä¸ª")
        
        # åº”ç”¨æ˜¾è‘—æ€§è¿‡æ»¤
        original_count = len(result['keypoints'])
        need_filter = (args.min_interval > 0 or args.top_k > 0 or 
                       args.energy_percentile > 0 or args.merge_close > 0 or
                       (args.segment_duration > 0 and args.segment_top_k > 0))
        
        if need_filter:
            print(f"\nğŸ” åº”ç”¨æ˜¾è‘—æ€§è¿‡æ»¤...")
            filtered_keypoints = filter_significant_keypoints(
                result['keypoints'],
                min_interval=args.min_interval,
                top_k=args.top_k,
                energy_percentile=args.energy_percentile,
                merge_close=args.merge_close,
                segment_duration=args.segment_duration,
                segment_top_k=args.segment_top_k
            )
            result['keypoints_original'] = result['keypoints']
            result['keypoints'] = filtered_keypoints
            print(f"  è¿‡æ»¤åå…³é”®ç‚¹: {len(filtered_keypoints)} ä¸ª (å‡å°‘äº† {original_count - len(filtered_keypoints)} ä¸ª)")
        
        # åŸºäº Caption æ®µè½è¿‡æ»¤
        if args.caption:
            if os.path.exists(args.caption):
                print(f"\nğŸ“‚ åŠ è½½ Caption æ®µè½ä¿¡æ¯: {args.caption}")
                sections = load_sections_from_caption(args.caption)
                
                if sections:
                    print(f"  å…±è§£æåˆ° {len(sections)} ä¸ªæ®µè½:")
                    for sec in sections:
                        print(f"    - {sec['name']}: {sec['start_time']:.1f}s - {sec['end_time']:.1f}s")
                    
                    # å…ˆåˆå¹¶ç›¸è¿‘ç‚¹ï¼ˆå¦‚æœè¿˜æ²¡åˆå¹¶è¿‡ï¼‰
                    keypoints_to_filter = result['keypoints']
                    if args.merge_close > 0 and 'keypoints_original' not in result:
                        # å·²ç»åœ¨å‰é¢åˆå¹¶è¿‡äº†
                        pass
                    elif args.merge_close <= 0:
                        # æ²¡è®¾ç½®åˆå¹¶ï¼Œè¿™é‡Œåšä¸€ä¸ªé»˜è®¤åˆå¹¶
                        print(f"\nğŸ” åˆå¹¶ç›¸è¿‘ç‚¹ (é»˜è®¤ merge_close=0.15s)...")
                        keypoints_to_filter = filter_significant_keypoints(
                            keypoints_to_filter,
                            merge_close=0.15
                        )
                    
                    filtered_keypoints = filter_by_sections(
                        keypoints_to_filter,
                        sections,
                        section_top_k=args.section_top_k,
                        section_min_interval=args.section_min_interval,
                        section_energy_percentile=args.section_energy_percentile
                    )
                    
                    if 'keypoints_original' not in result:
                        result['keypoints_original'] = result['keypoints']
                    result['keypoints'] = filtered_keypoints
                    result['sections'] = sections
                else:
                    print(f"  âš ï¸ æœªèƒ½ä» caption æ–‡ä»¶è§£æåˆ°æœ‰æ•ˆæ®µè½")
            else:
                print(f"  âš ï¸ Caption æ–‡ä»¶ä¸å­˜åœ¨: {args.caption}")
        
        print(f"\nå‰ 15 ä¸ªå…³é”®ç‚¹:")
        print(f"{'æ—¶é—´(ç§’)':>10} | {'ç±»å‹':<25} | {'å¼ºåº¦':>6}")
        print("-" * 50)
        for pt in result['keypoints'][:15]:
            print(f"{pt['time']:10.3f} | {pt['type']:<25} | {pt['intensity']:6.2f}")
        
        if len(result['keypoints']) > 15:
            print(f"  ... (å…± {len(result['keypoints'])} ä¸ªå…³é”®ç‚¹)")

        # å¯è§†åŒ–
        if args.visualize:
            print(f"\næ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾ç‰‡...")
            
            if args.output and not args.video:
                output_path = args.output
            else:
                audio_file = Path(args.audio_path)
                output_path = audio_file.parent / f"{audio_file.stem}_madmom_thr{args.onset_threshold}_kp{len(result['keypoints'])}.png"
            
            visualize_keypoints(
                audio_path=args.audio_path,
                result=result,
                output_path=str(output_path),
                show_beats=args.show_beats,
                show_onsets=args.show_onsets
            )

        # ç”Ÿæˆé¢œè‰²å˜åŒ–è§†é¢‘
        if args.video:
            print(f"\næ­£åœ¨ç”Ÿæˆé¢œè‰²å˜åŒ–è§†é¢‘...")

            # è§£æåˆ†è¾¨ç‡
            try:
                width, height = map(int, args.resolution.split('x'))
                resolution = (width, height)
            except ValueError:
                print(f"âš ï¸  æ— æ•ˆçš„åˆ†è¾¨ç‡æ ¼å¼ '{args.resolution}'ï¼Œä½¿ç”¨é»˜è®¤å€¼ 1920x1080")
                resolution = (1920, 1080)

            # é€‰æ‹©å…³é”®ç‚¹
            if args.downbeats_only:
                keypoints = [{'time': t} for t in result['downbeats']]
                suffix = "_downbeats"
            else:
                keypoints = result['keypoints']
                suffix = ""

            # ç¡®å®šè¾“å‡ºè·¯å¾„
            if args.output:
                video_output_path = args.output
            else:
                audio_file = Path(args.audio_path)
                video_output_path = audio_file.parent / f"{audio_file.stem}_madmom_thr{args.onset_threshold}_kp{len(keypoints)}{suffix}.mp4"

            # æ„å»ºå‚æ•°ä¿¡æ¯å­—å…¸
            params_info = {
                'onset_threshold': args.onset_threshold,
                'beats_per_bar': args.beats_per_bar,
                'bpm_range': f'{args.min_bpm}-{args.max_bpm}',
                'transition_lambda': args.transition_lambda,
                'key': result['meta']['key'],
                'emotion': result['meta']['emotion_clue'],
                'n_keypoints': len(keypoints),
            }

            generate_color_video(
                audio_path=args.audio_path,
                keypoints=keypoints,
                output_path=str(video_output_path),
                fps=args.video_fps,
                resolution=resolution,
                params_info=params_info
            )

    except Exception as e:
        import traceback
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        print("\nè¯·ç¡®ä¿å·²å®‰è£… madmom å’Œ ffmpeg")
        return

    return result


# --- ä½¿ç”¨ç¤ºä¾‹ ---
if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤ç¤ºä¾‹
    if len(sys.argv) == 1:
        print("ç”¨æ³•: python audio_Madmom.py <éŸ³é¢‘æ–‡ä»¶è·¯å¾„> [é€‰é¡¹]")
        print("ä½¿ç”¨ --help æŸ¥çœ‹è¯¦ç»†å¸®åŠ©")
        sys.exit(0)
    
    main()